<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><title>Projects | LAION</title><meta name="title" content="Projects | LAION"/><meta property="og:title" content="Projects | LAION"/><meta name="twitter:title" content="Projects | LAION"/><meta name="description" content="A selection of open-source projects maintained by LAION, the Large-scale Artificial Intelligence Open Network, to be used freely in machine learning efforts."/><meta property="og:description" content="A selection of open-source projects maintained by LAION, the Large-scale Artificial Intelligence Open Network, to be used freely in machine learning efforts."/><meta name="twitter:description" content="A selection of open-source projects maintained by LAION, the Large-scale Artificial Intelligence Open Network, to be used freely in machine learning efforts."/><meta property="og:image" content="https://laion.ai/social.png"/><meta name="twitter:image" content="https://laion.ai/social.png"/><meta name="twitter:image:alt" content="The text: LAION. Large-scale Artificial Intelligence Open Network, TRULY OPEN AI. 100% NON-PROFIT. 100% FREE."/><meta property="og:type" content="website"/><meta property="og:url" content="https://laion.ai/projects"/><meta name="twitter:url" content="https://laion.ai/projects"/><meta name="twitter:card" content="summary_large_image"/><meta name="viewport" content="initial-scale=1.0, width=device-width"/><meta name="theme-color" content="#1D374E"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon.png"/><link rel="icon" href="/favicon.svg" type="image/svg+xml"/><link rel="preload" href="/fonts/DinishCondensed-Bold.woff" as="font" type="font/woff" crossorigin="true"/><link rel="preload" href="/fonts/DinishCondensed-Bold.woff2" as="font" type="font/woff2" crossorigin="true"/><link rel="preload" href="/fonts/Dinish-Regular.woff" as="font" type="font/woff" crossorigin="true"/><link rel="preload" href="/fonts/Dinish-Regular.woff2" as="font" type="font/woff2" crossorigin="true"/><link rel="preload" href="/fonts/Dinish-Italic.woff" as="font" type="font/woff" crossorigin="true"/><link rel="preload" href="/fonts/Dinish-Italic.woff2" as="font" type="font/woff2" crossorigin="true"/><meta name="next-head-count" content="25"/><link rel="stylesheet" href="/fonts/load.css"/><link rel="preload" href="/_next/static/css/5357c8cce67e7f29.css" as="style"/><link rel="stylesheet" href="/_next/static/css/5357c8cce67e7f29.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-5752944655d749a0.js" defer=""></script><script src="/_next/static/chunks/framework-a87821de553db91d.js" defer=""></script><script src="/_next/static/chunks/main-6a269cfcb9446759.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fb0512e25146295.js" defer=""></script><script src="/_next/static/chunks/pages/projects-4cdccd5cc4d4eaf7.js" defer=""></script><script src="/_next/static/DoZpDVviVPWYGDgPamR_P/_buildManifest.js" defer=""></script><script src="/_next/static/DoZpDVviVPWYGDgPamR_P/_ssgManifest.js" defer=""></script><script src="/_next/static/DoZpDVviVPWYGDgPamR_P/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><div class="w-screen full-container flex-col md:flex-row flex "><div class="md:basis-1/5 "><div class="navbar fixed w-full flex md:flex-col px-4 md:px-6 py-2 md:py-6 md:pb-7 z-30 bg-sky text-paper md:h-full items-center justify-between md:static md:w-auto md:bg-paper md:text-sky md:max-h-screen md:justify-between child:pl-2 child:md:pl-0 child:text-lg "><div><p class="text-4xl md:text-7xl cursor-pointer font-bold pl-0 md:pb-3">LAION</p><div class="md:flex child:pl-3 md:text-xl child:md:pl-1 child:md:pt-2 hidden md:flex-col child:brightness-100 child:transition"><a href="/projects/">Projects</a><a href="/team/">Team</a><a href="/blog/">Blog</a><a href="/notes/">Notes</a><a href="/press/">Press</a><a href="/about/">About</a><a href="/faq/">FAQ</a><a href="/donations/">Donations</a><a href="/privacy-policy/">Privacy Policy</a><a href="/dataset-requests/">Dataset Requests</a><a href="/impressum/">Impressum</a></div></div><div class="child:mr-3 -ml-0.5 child:w-8 child:brightness-100 child:transition hidden md:flex"><a href="mailto:contact@laion.ai" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg></a><a href="https://discord.com/invite/eq3cAMZtCC" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a><a href="https://github.com/LAION-AI/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></div><div class="md:hidden"><div><div class="bm-overlay" style="position:fixed;z-index:1000;width:100%;height:100%;background:rgba(0, 0, 0, 0.3);opacity:0;-moz-transform:translate3d(100%, 0, 0);-ms-transform:translate3d(100%, 0, 0);-o-transform:translate3d(100%, 0, 0);-webkit-transform:translate3d(100%, 0, 0);transform:translate3d(100%, 0, 0);transition:opacity 0.3s, transform 0s 0.3s;top:0px;left:0px"></div><div><div class="bm-burger-button" style="z-index:1000;position:fixed;width:1.2em;height:1.0em;right:1.2rem;top:1em"><button type="button" id="react-burger-menu-btn" style="position:absolute;left:0;top:0;z-index:1;width:100%;height:100%;margin:0;padding:0;border:none;font-size:0;background:transparent;cursor:pointer">Open Menu</button><span><span class="bm-burger-bars" style="position:absolute;height:20%;left:0;right:0;top:0%;opacity:1;background:#fff"></span><span class="bm-burger-bars" style="position:absolute;height:20%;left:0;right:0;top:40%;opacity:1;background:#fff"></span><span class="bm-burger-bars" style="position:absolute;height:20%;left:0;right:0;top:80%;opacity:1;background:#fff"></span></span></div></div><div id="" class="bm-menu-wrap" style="position:fixed;right:0;z-index:1100;width:300px;height:100%;-moz-transform:translate3d(100%, 0, 0);-ms-transform:translate3d(100%, 0, 0);-o-transform:translate3d(100%, 0, 0);-webkit-transform:translate3d(100%, 0, 0);transform:translate3d(100%, 0, 0);transition:all 0.5s;top:0px" aria-hidden="true"><div class="bm-menu" style="height:100%;box-sizing:border-box;overflow:auto;background:#1D374E;padding:2.5em 1.5em 0"><nav class="bm-item-list" style="height:100%;color:#fff;padding:0.8em"><div class="bm-item" style="display:inline-block" tabindex="-1"><div class="child:pb-2 child:child:text-2xl"><p><a href="/projects/">Projects</a></p><p><a href="/team/">Team</a></p><p><a href="/blog/">Blog</a></p><p><a href="/notes/">Notes</a></p><p><a href="/press/">Press</a></p><p><a href="/about/">About</a></p><p><a href="/faq/">FAQ</a></p><p><a href="/donations/">Donations</a></p><p><a href="/privacy-policy/">Privacy Policy</a></p><p><a href="/dataset-requests/">Dataset Requests</a></p><p><a href="/impressum/">Impressum</a></p></div><div class="child:mr-3 pt-4 child:w-8 child:brightness-100 hover:child:brightness-90 child:transition flex"><a href="mailto:contact@laion.ai" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg></a><a href="https://discord.com/invite/eq3cAMZtCC" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a><a href="https://github.com/LAION-AI/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></div></div></nav></div><div><div class="bm-cross-button" style="position:absolute;width:24px;height:24px;right:8px;top:8px"><button type="button" id="react-burger-cross-btn" style="position:absolute;left:0;top:0;z-index:1;width:100%;height:100%;margin:0;padding:0;border:none;font-size:0;background:transparent;cursor:pointer" tabindex="-1">Close Menu</button><span style="position:absolute;top:6px;right:14px"><span class="bm-cross" style="position:absolute;width:3px;height:14px;transform:rotate(45deg);background:#fff"></span><span class="bm-cross" style="position:absolute;width:3px;height:14px;transform:rotate(-45deg);background:#fff"></span></span></div></div></div></div></div></div></div><div id="content" class="md:overflow-y-scroll md:max-h-screen md:z-50 md:shadow-lg shadow-neutral-600/70 text-paper grow md:grow-0 md:basis-4/5 flex child:grow flex-col "><div class="" style="opacity:0"><div class="w-full flex justify-center py-5 pt-16 md:pt-5"><div class="container px-5"><h1 class="text-7xl md:text-8xl font-bold">PROJECTS</h1><hr class="mb-5 mt-2 md:hidden"/><div><h3 class="pb-4 pt-0">DATASETS</h3><div class="grid gap-5 grid-cols-2"><a class="no-underline col-span-2"><div class=" bg-sky border border-paper hover:bg-paper hover:text-sky cursor-pointer transition-colors p-5 shadow-lg shadow-neutral-800/20 flex flex-col sm:flex-row "><div class="basis-1/4"><p class="text-2xl">LAION-400M</p><p>image/text</p><p></p><p>Status: <!-- -->Released<!-- --></p></div><hr class="mt-4 mb-4 sm:hidden false"/><div class="basis-3/4 false">Formerly known as crawling@home (C@H), an openly accessible 400M image-text-pair dataset.</div></div></a><a class="no-underline col-span-2"><div class=" bg-sky border border-paper hover:bg-paper hover:text-sky cursor-pointer transition-colors p-5 shadow-lg shadow-neutral-800/20 flex flex-col sm:flex-row "><div class="basis-1/4"><p class="text-2xl">LAION5B</p><p>image/text</p><p></p><p>Status: <!-- -->Released<!-- --></p></div><hr class="mt-4 mb-4 sm:hidden false"/><div class="basis-3/4 false">A dataset consisting of 5.85 billion CLIP-filtered image-text pairs, featuring several nearest neighbor indices, an improved web-interface for exploration and subset generation, and detection scores for watermark, NSFW, and toxic content detection.</div></div></a><a class="no-underline col-span-2"><div class=" bg-sky border border-paper hover:bg-paper hover:text-sky cursor-pointer transition-colors p-5 shadow-lg shadow-neutral-800/20 flex flex-col sm:flex-row "><div class="basis-1/4"><p class="text-2xl">Laion-coco</p><p>image/text</p><p></p><p>Status: <!-- -->Released<!-- --></p></div><hr class="mt-4 mb-4 sm:hidden false"/><div class="basis-3/4 false">600M captions generated using BLIP from Laion2B-en.</div></div></a><a class="no-underline col-span-2"><div class=" bg-sky border border-paper hover:bg-paper hover:text-sky cursor-pointer transition-colors p-5 shadow-lg shadow-neutral-800/20 flex flex-col sm:flex-row "><div class="basis-1/4"><p class="text-2xl">Laion translated</p><p>image/text</p><p></p><p>Status: <!-- -->Released<!-- --></p></div><hr class="mt-4 mb-4 sm:hidden false"/><div class="basis-3/4 false">3B translated samples from Laion5B.</div></div></a><a class="no-underline col-span-2"><div class=" bg-sky border border-paper hover:bg-paper hover:text-sky cursor-pointer transition-colors p-5 shadow-lg shadow-neutral-800/20 flex flex-col sm:flex-row "><div class="basis-1/4"><p class="text-2xl">Clip H/14</p><p>image/text</p><p></p><p>Status: <!-- -->Released<!-- --></p></div><hr class="mt-4 mb-4 sm:hidden false"/><div class="basis-3/4 false">The largest open source clip.</div></div></a><a href="https://huggingface.co/datasets/laion/laion-high-resolution" rel="noopener noreferrer" target="_blank" class="no-underline col-span-2"><div class=" bg-sky border border-paper hover:bg-paper hover:text-sky cursor-pointer transition-colors p-5 shadow-lg shadow-neutral-800/20 flex flex-col sm:flex-row "><div class="basis-1/4"><p class="text-2xl">LAION5B High-Res</p><p>image/text</p><p></p><p>Status: <!-- -->Released<!-- --></p></div><hr class="mt-4 mb-4 sm:hidden false"/><div class="basis-3/4 false">A subset of the LAION5B database, with high resolution images over 1024x1024, containing 170 million samples.</div></div></a><a href="https://github.com/LAION-AI/laion-datasets/blob/main/laion-aesthetic.md" rel="noopener noreferrer" target="_blank" class="no-underline col-span-2"><div class=" bg-sky border border-paper hover:bg-paper hover:text-sky cursor-pointer transition-colors p-5 shadow-lg shadow-neutral-800/20 flex flex-col sm:flex-row "><div class="basis-1/4"><p class="text-2xl">LAION Aesthetics</p><p>image/text</p><p></p><p>Status: <!-- -->Released<!-- --></p></div><hr class="mt-4 mb-4 sm:hidden false"/><div class="basis-3/4 false">A subset of LAION5B that has been estimated by a model trained on top of clip embeddings to contain only aestheticly pleasing images.</div></div></a><a href="https://github.com/LAION-AI/laion-3d" rel="noopener noreferrer" target="_blank" class="no-underline col-span-2"><div class=" bg-sky border border-paper hover:bg-paper hover:text-sky cursor-pointer transition-colors p-5 shadow-lg shadow-neutral-800/20 flex flex-col sm:flex-row "><div class="basis-1/4"><p class="text-2xl">LAION-3D</p><p>3d/image/text</p><p></p><p>Status: <!-- -->Started<!-- --></p></div><hr class="mt-4 mb-4 sm:hidden false"/><div class="basis-3/4 false">An effort to create a large-scale dataset consisting of 3D models and descriptor pairs.</div></div></a><a href="https://github.com/LAION-AI/audio-dataset" rel="noopener noreferrer" target="_blank" class="no-underline col-span-2"><div class=" bg-sky border border-paper hover:bg-paper hover:text-sky cursor-pointer transition-colors p-5 shadow-lg shadow-neutral-800/20 flex flex-col sm:flex-row "><div class="basis-1/4"><p class="text-2xl">Audio Dataset</p><p>text/audio</p><p></p><p>Status: <!-- -->Started<!-- --></p></div><hr class="mt-4 mb-4 sm:hidden false"/><div class="basis-3/4 false">An audio dataset for training CLAP and other models, containing a raw and processed dataset, the latter containing .flac files with captions, labels, and other metadata.</div></div></a><a href="https://github.com/LAION-AI/watermark-detection" rel="noopener noreferrer" target="_blank" class="no-underline col-span-2"><div class=" bg-sky border border-paper hover:bg-paper hover:text-sky cursor-pointer transition-colors p-5 shadow-lg shadow-neutral-800/20 flex flex-col sm:flex-row "><div class="basis-1/4"><p class="text-2xl">Watermark Detection</p><p>image/text</p><p>Contrastive</p><p>Status: <!-- -->Released<!-- --></p></div><hr class="mt-4 mb-4 sm:hidden false"/><div class="basis-3/4 false">A repository containing datasets to train a watermark classifier.</div></div></a></div></div><div><h3 class="pb-4 pt-5">MODELS</h3><div class="grid gap-5 grid-cols-2"><a href="https://github.com/mlfoundations/open_clip" rel="noopener noreferrer" target="_blank" class="no-underline col-span-2"><div class=" bg-sky border border-paper hover:bg-paper hover:text-sky cursor-pointer transition-colors p-5 shadow-lg shadow-neutral-800/20 flex flex-col sm:flex-row "><div class="basis-1/4"><p class="text-2xl">Openclip</p><p>image/text</p><p>Contrastive</p><p>Status: <!-- -->released<!-- --></p></div><hr class="mt-4 mb-4 sm:hidden false"/><div class="basis-3/4 false">An open source implementation of OpenAI&#x27;s CLIP (Contrastive Language-Image Pre-training).</div></div></a><a href="https://github.com/lucidrains/DALLE2-pytorch" rel="noopener noreferrer" target="_blank" class="no-underline col-span-2"><div class=" bg-sky border border-paper hover:bg-paper hover:text-sky cursor-pointer transition-colors p-5 shadow-lg shadow-neutral-800/20 flex flex-col sm:flex-row "><div class="basis-1/4"><p class="text-2xl">DALLE-2 Prior/Decoder</p><p>image/text</p><p>Generative</p><p>Status: <!-- -->Started<!-- --></p></div><hr class="mt-4 mb-4 sm:hidden false"/><div class="basis-3/4 false">An implementation of DALL-E 2, OpenAI&#x27;s text-to-image synthesis neural network, in Pytorch.</div></div></a><a href="https://github.com/TheoCoombes/ClipCap" rel="noopener noreferrer" target="_blank" class="no-underline col-span-2"><div class=" bg-sky border border-paper hover:bg-paper hover:text-sky cursor-pointer transition-colors p-5 shadow-lg shadow-neutral-800/20 flex flex-col sm:flex-row "><div class="basis-1/4"><p class="text-2xl">ClipCap</p><p>image/text</p><p>Generative</p><p>Status: <!-- -->Released<!-- --></p></div><hr class="mt-4 mb-4 sm:hidden false"/><div class="basis-3/4 false">Generate text from embedding, using pretrained encoder and language models.</div></div></a><a href="https://github.com/LAION-AI/CLAP" rel="noopener noreferrer" target="_blank" class="no-underline col-span-2"><div class=" bg-sky border border-paper hover:bg-paper hover:text-sky cursor-pointer transition-colors p-5 shadow-lg shadow-neutral-800/20 flex flex-col sm:flex-row "><div class="basis-1/4"><p class="text-2xl">CLAP</p><p>audio/text</p><p>Contrastive</p><p>Status: <!-- -->Started<!-- --></p></div><hr class="mt-4 mb-4 sm:hidden false"/><div class="basis-3/4 false">A Contrastive Language-Audio Pretraining model, like CLIP, for audio.</div></div></a><a href="https://github.com/LAION-AI/video-clip" rel="noopener noreferrer" target="_blank" class="no-underline col-span-2"><div class=" bg-sky border border-paper hover:bg-paper hover:text-sky cursor-pointer transition-colors p-5 shadow-lg shadow-neutral-800/20 flex flex-col sm:flex-row "><div class="basis-1/4"><p class="text-2xl">Video CLIP</p><p>video/text</p><p>Contrastive</p><p>Status: <!-- -->Planning<!-- --></p></div><hr class="mt-4 mb-4 sm:hidden false"/><div class="basis-3/4 false">A contrastive language pretraining model for videos.</div></div></a><a href="https://github.com/FreddeFrallan/Multilingual-CLIP" rel="noopener noreferrer" target="_blank" class="no-underline col-span-2"><div class=" bg-sky border border-paper hover:bg-paper hover:text-sky cursor-pointer transition-colors p-5 shadow-lg shadow-neutral-800/20 flex flex-col sm:flex-row "><div class="basis-1/4"><p class="text-2xl">Multilingual-CLIP</p><p>image/text</p><p>Contrastive</p><p>Status: <!-- -->In progress<!-- --></p></div><hr class="mt-4 mb-4 sm:hidden false"/><div class="basis-3/4 false">An implementation of OpenAI&#x27;s CLIP text encoders for any language.</div></div></a><a href="https://github.com/LAION-AI/CLIP-based-NSFW-Detector" rel="noopener noreferrer" target="_blank" class="no-underline col-span-2"><div class=" bg-sky border border-paper hover:bg-paper hover:text-sky cursor-pointer transition-colors p-5 shadow-lg shadow-neutral-800/20 flex flex-col sm:flex-row "><div class="basis-1/4"><p class="text-2xl">NSFW Detection</p><p>image/text</p><p>Contrastive</p><p>Status: <!-- -->Released<!-- --></p></div><hr class="mt-4 mb-4 sm:hidden false"/><div class="basis-3/4 false">A detector for not safe for work content within images using CLIP.</div></div></a><a href="https://github.com/LAION-AI/the-big-plan/blob/main/projects/electric-sheep.md" rel="noopener noreferrer" target="_blank" class="no-underline col-span-2"><div class=" bg-sky border border-paper hover:bg-paper hover:text-sky cursor-pointer transition-colors p-5 shadow-lg shadow-neutral-800/20 flex flex-col sm:flex-row "><div class="basis-1/4"><p class="text-2xl">Electric Sheep</p><p>image/text/audio/video</p><p>Contrastive/Generative</p><p>Status: <!-- -->Started<!-- --></p></div><hr class="mt-4 mb-4 sm:hidden false"/><div class="basis-3/4 false">Train Contrastive and generative models on all modalities.</div></div></a></div></div><div><h3 class="pb-4 pt-5">TOOLS</h3><div class="grid gap-5 grid-cols-2"><a href="https://github.com/rom1504/img2dataset" rel="noopener noreferrer" target="_blank" class="no-underline col-span-2"><div class=" bg-sky border border-paper hover:bg-paper hover:text-sky cursor-pointer transition-colors p-5 shadow-lg shadow-neutral-800/20 flex flex-col sm:flex-row "><div class="basis-1/4"><p class="text-2xl">img2dataset</p><p>image/text</p><p></p><p>Status: <!-- -->Released<!-- --></p></div><hr class="mt-4 mb-4 sm:hidden false"/><div class="basis-3/4 false">A tool which allows a user to turn large sets of image urls to an image dataset. Can download, resize and package 100M urls in 20 hours on one machine.</div></div></a><a href="https://github.com/rom1504/clip-retrieval" rel="noopener noreferrer" target="_blank" class="no-underline col-span-2"><div class=" bg-sky border border-paper hover:bg-paper hover:text-sky cursor-pointer transition-colors p-5 shadow-lg shadow-neutral-800/20 flex flex-col sm:flex-row "><div class="basis-1/4"><p class="text-2xl">Clip Retrieval</p><p>image/text</p><p></p><p>Status: <!-- -->Released<!-- --></p></div><hr class="mt-4 mb-4 sm:hidden false"/><div class="basis-3/4 false">Allows a user to easily compute clip embeddings and build a clip retrieval system with them. 100M text+image embeddings can be processed in 20 hours using a RTX 3080.</div></div></a><a href="https://github.com/rvencu/crawlingathome-gpu-hcloud" rel="noopener noreferrer" target="_blank" class="no-underline col-span-2"><div class=" bg-sky border border-paper hover:bg-paper hover:text-sky cursor-pointer transition-colors p-5 shadow-lg shadow-neutral-800/20 flex flex-col sm:flex-row "><div class="basis-1/4"><p class="text-2xl">Crawlingathome-gpu-hcloud</p><p>image/text</p><p></p><p>Status: <!-- -->Released<!-- --></p></div><hr class="mt-4 mb-4 sm:hidden false"/><div class="basis-3/4 false">GPU controlled Hetzner Cloud workers swarm for Crawling@Home project.</div></div></a><a href="https://github.com/LAION-AI/CLIP_benchmark" rel="noopener noreferrer" target="_blank" class="no-underline col-span-2"><div class=" bg-sky border border-paper hover:bg-paper hover:text-sky cursor-pointer transition-colors p-5 shadow-lg shadow-neutral-800/20 flex flex-col sm:flex-row "><div class="basis-1/4"><p class="text-2xl">Clip Benchmark</p><p>image/text</p><p></p><p>Status: <!-- -->In Progress<!-- --></p></div><hr class="mt-4 mb-4 sm:hidden false"/><div class="basis-3/4 false">Evaluating CLIP-like models on a standard set of datasets on different tasks such as zero-shot classification and zero-shot retrieval.</div></div></a></div></div><div><h3 class="pb-4 pt-5">PAPERS</h3><div class="grid gap-5 grid-cols-2"><a href="https://arxiv.org/abs/2111.02114" rel="noopener noreferrer" target="_blank" class="no-underline col-span-1"><div class=" bg-sky border border-paper hover:bg-paper hover:text-sky cursor-pointer transition-colors p-5 shadow-lg shadow-neutral-800/20 flex flex-col sm:flex-row "><div><p class="text-2xl">LAION-400M</p><p>image/text</p><p></p><p>Status: <!-- -->Published<!-- --></p></div><hr class="mt-4 mb-4 sm:hidden hidden"/><div class="basis-3/4 hidden"></div></div></a><a href="https://github.com/LAION-AI/laion5B-paper" rel="noopener noreferrer" target="_blank" class="no-underline col-span-1"><div class=" bg-sky border border-paper hover:bg-paper hover:text-sky cursor-pointer transition-colors p-5 shadow-lg shadow-neutral-800/20 flex flex-col sm:flex-row "><div><p class="text-2xl">LAION-5B</p><p>image/text</p><p></p><p>Status: <!-- -->started<!-- --></p></div><hr class="mt-4 mb-4 sm:hidden hidden"/><div class="basis-3/4 hidden"></div></div></a></div></div></div></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{}},"page":"/projects","query":{},"buildId":"DoZpDVviVPWYGDgPamR_P","nextExport":true,"autoExport":true,"isFallback":false,"scriptLoader":[]}</script></body></html>