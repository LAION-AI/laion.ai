<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><title>Game Reasoning Arena: Inside the Mind of AI: How LLMs Think, Strategize, and Compete in Real-Time | LAION</title><meta name="title" content="Game Reasoning Arena: Inside the Mind of AI: How LLMs Think, Strategize, and Compete in Real-Time | LAION"/><meta property="og:title" content="Game Reasoning Arena: Inside the Mind of AI: How LLMs Think, Strategize, and Compete in Real-Time | LAION"/><meta name="twitter:title" content="Game Reasoning Arena: Inside the Mind of AI: How LLMs Think, Strategize, and Compete in Real-Time | LAION"/><meta name="description" content="&lt;h3&gt;&lt;a id=&quot;access&quot; class=&quot;anchor&quot; href=&quot;#access&quot; aria-hidden=&quot;true&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; class=&quot;octicon octicon-link&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewbox=&quot;0..."/><meta property="og:description" content="&lt;h3&gt;&lt;a id=&quot;access&quot; class=&quot;anchor&quot; href=&quot;#access&quot; aria-hidden=&quot;true&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; class=&quot;octicon octicon-link&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewbox=&quot;0..."/><meta name="twitter:description" content="&lt;h3&gt;&lt;a id=&quot;access&quot; class=&quot;anchor&quot; href=&quot;#access&quot; aria-hidden=&quot;true&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; class=&quot;octicon octicon-link&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewbox=&quot;0..."/><meta property="og:image" content="https://laion.ai/images/blog/game_reasoning_arena/0_blog_logo.png"/><meta name="twitter:image" content="https://laion.ai/images/blog/game_reasoning_arena/0_blog_logo.png"/><meta name="twitter:image:alt" content="The text: LAION. Large-scale Artificial Intelligence Open Network, TRULY OPEN AI. 100% NON-PROFIT. 100% FREE."/><meta property="og:type" content="website"/><meta property="og:url" content="https://laion.ai/blog/board_game_arena_blog_post"/><meta name="twitter:url" content="https://laion.ai/blog/board_game_arena_blog_post"/><meta name="twitter:card" content="summary_large_image"/><meta name="viewport" content="initial-scale=1.0, width=device-width"/><meta name="theme-color" content="#1D374E"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon.png"/><link rel="icon" href="/favicon.svg" type="image/svg+xml"/><link rel="preload" href="/fonts/DinishCondensed-Bold.woff" as="font" type="font/woff" crossorigin="true"/><link rel="preload" href="/fonts/DinishCondensed-Bold.woff2" as="font" type="font/woff2" crossorigin="true"/><link rel="preload" href="/fonts/Dinish-Regular.woff" as="font" type="font/woff" crossorigin="true"/><link rel="preload" href="/fonts/Dinish-Regular.woff2" as="font" type="font/woff2" crossorigin="true"/><link rel="preload" href="/fonts/Dinish-Italic.woff" as="font" type="font/woff" crossorigin="true"/><link rel="preload" href="/fonts/Dinish-Italic.woff2" as="font" type="font/woff2" crossorigin="true"/><meta name="next-head-count" content="25"/><link rel="stylesheet" href="/fonts/load.css"/><link rel="preload" href="/_next/static/css/5357c8cce67e7f29.css" as="style"/><link rel="stylesheet" href="/_next/static/css/5357c8cce67e7f29.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-5752944655d749a0.js" defer=""></script><script src="/_next/static/chunks/framework-a87821de553db91d.js" defer=""></script><script src="/_next/static/chunks/main-6a269cfcb9446759.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fb0512e25146295.js" defer=""></script><script src="/_next/static/chunks/286-30519d8a3e60551d.js" defer=""></script><script src="/_next/static/chunks/807-a4eae1dfa8bfbe9f.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-44fac0971625f498.js" defer=""></script><script src="/_next/static/RUv6f7SBqEtJtqqMGa8sZ/_buildManifest.js" defer=""></script><script src="/_next/static/RUv6f7SBqEtJtqqMGa8sZ/_ssgManifest.js" defer=""></script><script src="/_next/static/RUv6f7SBqEtJtqqMGa8sZ/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><div class="w-screen full-container flex-col md:flex-row flex "><div class="md:basis-1/5 "><div class="navbar fixed w-full flex md:flex-col px-4 md:px-6 py-2 md:py-6 md:pb-7 z-30 bg-sky text-paper md:h-full items-center justify-between md:static md:w-auto md:bg-paper md:text-sky md:max-h-screen md:justify-between child:pl-2 child:md:pl-0 child:text-lg "><div><p class="text-4xl md:text-7xl cursor-pointer font-bold pl-0 md:pb-3">LAION</p><div class="md:flex child:pl-3 md:text-xl child:md:pl-1 child:md:pt-2 hidden md:flex-col child:brightness-100 child:transition"><a href="/projects/">Projects</a><a href="/team/">Team</a><a href="/blog/">Blog</a><a href="/notes/">Notes</a><a href="/press/">Press</a><a href="/about/">About</a><a href="/faq/">FAQ</a><a href="/donations/">Donations</a><a href="/privacy-policy/">Privacy Policy</a><a href="/dataset-requests/">Dataset Requests</a><a href="/impressum/">Impressum</a></div></div><div class="child:mr-3 -ml-0.5 child:w-8 child:brightness-100 child:transition hidden md:flex"><a href="mailto:contact@laion.ai" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg></a><a href="https://discord.com/invite/eq3cAMZtCC" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a><a href="https://github.com/LAION-AI/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></div><div class="md:hidden"><div><div class="bm-overlay" style="position:fixed;z-index:1000;width:100%;height:100%;background:rgba(0, 0, 0, 0.3);opacity:0;-moz-transform:translate3d(100%, 0, 0);-ms-transform:translate3d(100%, 0, 0);-o-transform:translate3d(100%, 0, 0);-webkit-transform:translate3d(100%, 0, 0);transform:translate3d(100%, 0, 0);transition:opacity 0.3s, transform 0s 0.3s;top:0px;left:0px"></div><div><div class="bm-burger-button" style="z-index:1000;position:fixed;width:1.2em;height:1.0em;right:1.2rem;top:1em"><button type="button" id="react-burger-menu-btn" style="position:absolute;left:0;top:0;z-index:1;width:100%;height:100%;margin:0;padding:0;border:none;font-size:0;background:transparent;cursor:pointer">Open Menu</button><span><span class="bm-burger-bars" style="position:absolute;height:20%;left:0;right:0;top:0%;opacity:1;background:#fff"></span><span class="bm-burger-bars" style="position:absolute;height:20%;left:0;right:0;top:40%;opacity:1;background:#fff"></span><span class="bm-burger-bars" style="position:absolute;height:20%;left:0;right:0;top:80%;opacity:1;background:#fff"></span></span></div></div><div id="" class="bm-menu-wrap" style="position:fixed;right:0;z-index:1100;width:300px;height:100%;-moz-transform:translate3d(100%, 0, 0);-ms-transform:translate3d(100%, 0, 0);-o-transform:translate3d(100%, 0, 0);-webkit-transform:translate3d(100%, 0, 0);transform:translate3d(100%, 0, 0);transition:all 0.5s;top:0px" aria-hidden="true"><div class="bm-menu" style="height:100%;box-sizing:border-box;overflow:auto;background:#1D374E;padding:2.5em 1.5em 0"><nav class="bm-item-list" style="height:100%;color:#fff;padding:0.8em"><div class="bm-item" style="display:inline-block" tabindex="-1"><div class="child:pb-2 child:child:text-2xl"><p><a href="/projects/">Projects</a></p><p><a href="/team/">Team</a></p><p><a href="/blog/">Blog</a></p><p><a href="/notes/">Notes</a></p><p><a href="/press/">Press</a></p><p><a href="/about/">About</a></p><p><a href="/faq/">FAQ</a></p><p><a href="/donations/">Donations</a></p><p><a href="/privacy-policy/">Privacy Policy</a></p><p><a href="/dataset-requests/">Dataset Requests</a></p><p><a href="/impressum/">Impressum</a></p></div><div class="child:mr-3 pt-4 child:w-8 child:brightness-100 hover:child:brightness-90 child:transition flex"><a href="mailto:contact@laion.ai" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg></a><a href="https://discord.com/invite/eq3cAMZtCC" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a><a href="https://github.com/LAION-AI/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></div></div></nav></div><div><div class="bm-cross-button" style="position:absolute;width:24px;height:24px;right:8px;top:8px"><button type="button" id="react-burger-cross-btn" style="position:absolute;left:0;top:0;z-index:1;width:100%;height:100%;margin:0;padding:0;border:none;font-size:0;background:transparent;cursor:pointer" tabindex="-1">Close Menu</button><span style="position:absolute;top:6px;right:14px"><span class="bm-cross" style="position:absolute;width:3px;height:14px;transform:rotate(45deg);background:#fff"></span><span class="bm-cross" style="position:absolute;width:3px;height:14px;transform:rotate(-45deg);background:#fff"></span></span></div></div></div></div></div></div></div><div id="content" class="md:overflow-y-scroll md:max-h-screen md:z-50 md:shadow-lg shadow-neutral-600/70 text-paper grow md:grow-0 md:basis-4/5 flex child:grow flex-col "><div class="" style="opacity:0"><div class="w-full flex justify-center py-5 pt-16 md:pt-5"><div class="container px-5" lang="en"><h1 lang="en" style="hyphens:auto" class="text-8xl md:text-8xl w-full font-bold title-flow break-words">GAME REASONING ARENA: INSIDE THE MIND OF AI: HOW LLMS THINK, STRATEGIZE, AND COMPETE IN REAL-TIME</h1><p class="text-2xl pb-2">by: <!-- -->Lucia Cipolina-Kun, Marianna Nezhurina, Jenia Jitsev<!-- -->,<!-- --> <!-- -->04 Aug, 2025<!-- --></p><hr/><div class="pt-2 article"><h3><a id="access" class="anchor" href="#access" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Access</h3>
<ul>
<li><strong>Repository</strong>: <a href="https://github.com/SLAMPAI/game_reasoning_arena">https://github.com/SLAMPAI/game_reasoning_arena</a></li>
<li><strong>Documentation</strong>: Complete installation, usage, and extension guides available at <a href="https://board-game-arena.readthedocs.io/en/latest/index.html">Game Reasoning Arena Documentation</a></li>
</ul>
<p>What happens when we peek inside an AI's mind while it's making strategic decisions? For the first time, we can watch Large Language Models think in real-time as they compete, strategize, and adapt in dynamic game environments. Our Game Reasoning Arena doesn't just test what AI can do—it reveals <em>how</em> AI thinks, capturing every reasoning step as models battle each other in strategic gameplay.</p>
<p><em>The first platform to expose AI's strategic DNA in action</em></p>
<p>Game Reasoning Arena is a research platform where Large Language Models battle in board games against other LLMs, humans, or random bots—while exposing every step of their strategic reasoning. Built on Google’s OpenSpiel with a modular, Gymnasium-style interface, it supports custom games, agents, and analysis tools. Scalable Ray-based parallelization powers large tournaments, making it a fast, flexible testbed for studying how AI thinks under competition and uncertainty.</p>
<hr>
<h3><a id="quick-start-with-google-colab" class="anchor" href="#quick-start-with-google-colab" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Quick start with Google Colab</h3>
<h2><a id="click-here-to-try-game-reasoning-arena-in-our-colab-now" class="anchor" href="#click-here-to-try-game-reasoning-arena-in-our-colab-now" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong><a href="https://github.com/SLAMPAI/game_reasoning_arena/blob/main/colabs/game_reasoning_arena.ipynb">Click here to try Game Reasoning Arena in our Colab now!</a></strong></h2>
<h2><a id="why-strategic-games-matter-for-ai-evaluation" class="anchor" href="#why-strategic-games-matter-for-ai-evaluation" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Why Strategic Games Matter for AI Evaluation</h2>
<p>Strategic games offer unique evaluation opportunities that traditional benchmarks cannot provide: genuine decision-making under uncertainty. When an LLM plays Tic-Tac-Toe, Connect Four, or Poker, it must:</p>
<ul>
<li>Analyze complex game states with multiple possible outcomes</li>
<li>Reason about opponent behavior and predict future moves</li>
<li>Balance short-term tactics with long-term strategic goals</li>
<li>Handle incomplete information and make decisions under pressure</li>
<li>Adapt strategies based on opponent responses</li>
</ul>
<p>This creates an ideal testing environment for evaluating the strategic reasoning capabilities that will be crucial as LLMs become more integrated into decision-making roles across industries.</p>
<h2><a id="key-features-of-game-reasoning-arena" class="anchor" href="#key-features-of-game-reasoning-arena" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Key Features of Game Reasoning Arena</h2>
<h3><a id="multi-agent-testing-framework" class="anchor" href="#multi-agent-testing-framework" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Multi-Agent Testing Framework</h3>
<p>Game Reasoning Arena supports comprehensive competitive scenarios:</p>
<ul>
<li><strong>LLM vs Random</strong>: Establish baseline performance against unpredictable opponents.</li>
<li><strong>LLM vs LLM</strong>: Direct strategic competitions between different language models.</li>
<li><strong>Self-Play</strong>: Enable LLMs to develop strategies by playing against themselves.</li>
<li><strong>Cross-Provider Tournaments</strong>: Compare models from different providers within the same game.</li>
</ul>
<h3><a id="diverse-game-library" class="anchor" href="#diverse-game-library" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Diverse Game Library</h3>
<p>The framework includes a carefully selected set of games that test different aspects of strategic thinking:</p>
<ul>
<li><strong><code>tic_tac_toe</code></strong> - Classic spatial reasoning and tactical planning</li>
<li><strong><code>connect_four</code></strong> - Long-term strategic positioning and pattern recognition</li>
<li><strong><code>kuhn_poker</code></strong> - Hidden information, bluffing, and probabilistic reasoning</li>
<li><strong><code>prisoners_dilemma</code></strong> - Cooperation versus competition dynamics</li>
<li><strong><code>matching_pennies</code></strong> - Zero-sum game theory and randomization strategies</li>
<li><strong><code>matrix_rps</code></strong> - Rock-paper-scissors with matrix representation</li>
<li><strong><code>hex</code></strong> -  Complex pathfinding and connection strategies on a hexagonal grid</li>
<li><strong><code>chess</code></strong> - Deep combinatorial reasoning, multi-phase planning, and tactical foresight</li>
</ul>
<p>Each game challenges LLMs in unique ways, from spatial reasoning to probabilistic thinking to social dynamics.</p>
<h3><a id="flexible-inference-architecture" class="anchor" href="#flexible-inference-architecture" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Flexible Inference Architecture</h3>
<p>One of Game Reasoning Arena's key strengths is its dual-backend architecture:</p>
<p><strong>LiteLLM Backend</strong> - Access to over 100 language models through APIs:</p>
<ul>
<li><strong>OpenAI</strong>: GPT-3.5, GPT-4, GPT-4 Turbo</li>
<li><strong>Anthropic</strong>: Claude 3, Claude 3.5 Sonnet</li>
<li><strong>Google</strong>: Gemini Pro, Gemma models</li>
<li><strong>Groq</strong>: Ultra-fast Llama 3 and Gemma inference</li>
<li><strong>Together AI</strong>: Llama 3.1, Mixtral, Code Llama</li>
<li><strong>Additional providers</strong>: Supporting over 90 other model providers for comprehensive comparison</li>
</ul>
<p><strong>vLLM Backend</strong> - Local GPU inference for:</p>
<ul>
<li>Complete control over model parameters</li>
<li>Privacy-sensitive research applications</li>
<li>Custom fine-tuned models</li>
<li>Cost-effective large-scale experiments</li>
</ul>
<p>It also supports Hugging Face backends.</p>
<p>The system allows researchers to mix different backends within the same experiment, enabling direct comparison between proprietary and open-source models, or between API-based and locally-hosted implementations.</p>
<h2><a id="reasoning-traces-understanding-ai-decision-making" class="anchor" href="#reasoning-traces-understanding-ai-decision-making" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Reasoning Traces: Understanding AI Decision-Making</h2>
<p>A particularly valuable feature of Game Reasoning Arena is its automatic reasoning traces capability. This functionality captures not only what move an LLM made, but also the reasoning behind that decision.</p>
<h3><a id="data-collection" class="anchor" href="#data-collection" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Data Collection</h3>
<p>For every move made by an LLM agent, Game Reasoning Arena automatically records:</p>
<ul>
<li><strong>Board State</strong>: The exact game position when the decision was made</li>
<li><strong>Agent Reasoning</strong>: The LLM's complete thought process and explanation</li>
<li><strong>Action Context</strong>: The chosen move with full metadata and timing</li>
<li><strong>Decision Patterns</strong>: Categorized reasoning types and strategic approaches</li>
</ul>
<h3><a id="example-reasoning-trace" class="anchor" href="#example-reasoning-trace" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Example Reasoning Trace</h3>
<p>Here is an example of the reasoning traces captured during gameplay:</p>
<pre><code>Reasoning Trace #1
----------------------------------------
Game: connect_four
Episode: 3, Turn: 5
Agent: litellm_groq/llama3-8b-8192
Action Chosen: 3

Board State at Decision Time:
     . . . . . . .
     . . . . . . .
     . . x . . . .
     . o x . . . .
     o x o . . . .
     x o x . . . .

Agent's Reasoning:
     I need to block the opponent's potential win. They have
     two pieces in column 2 and if I don't act now, they
     could get three in a row vertically. Playing column 3
     also gives me a chance to build my own threat
     horizontally while staying defensive.

Timestamp: 2025-08-04 14:23:17
</code></pre>
<h3><a id="analysis-tools" class="anchor" href="#analysis-tools" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Analysis Tools</h3>
<p>Game Reasoning Arena includes comprehensive analysis capabilities for reasoning traces:</p>
<ul>
<li><strong>Reasoning Categorization</strong>: Automatically classifies thinking patterns (Positional, Blocking, Winning Logic, Opponent Modeling, etc.)</li>
<li><strong>Pattern Visualization</strong>: Word clouds showing common reasoning terms, pie charts of strategy types</li>
<li><strong>Performance Heatmaps</strong>: Visual maps showing move preferences and strategic tendencies</li>
<li><strong>Statistical Analysis</strong>: Quantitative measures of decision-making patterns</li>
</ul>
<p>This provides researchers with tools for understanding how different LLMs approach strategic problems, what reasoning patterns correlate with success, and where current models have strategic limitations.</p>
<h2><a id="distributed-computing-and-scalability" class="anchor" href="#distributed-computing-and-scalability" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Distributed Computing and Scalability</h2>
<p>Game Reasoning Arena supports large-scale experiments through distributed computing capabilities:</p>
<h3><a id="ray-integration" class="anchor" href="#ray-integration" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Ray Integration</h3>
<ul>
<li><strong>Parallel Episodes</strong>: Execute multiple games simultaneously across different cores</li>
<li><strong>Multi-Game Tournaments</strong>: Run complex tournament brackets in parallel</li>
<li><strong>Distributed LLM Inference</strong>: Efficiently batch and distribute model calls</li>
<li><strong>Real-time Monitoring</strong>: Ray dashboard for live experiment tracking</li>
</ul>
<h3><a id="slurm-cluster-support" class="anchor" href="#slurm-cluster-support" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>SLURM Cluster Support</h3>
<p>Game Reasoning Arena integrates seamlessly with SLURM clusters, enabling researchers to conduct large-scale academic experiments with ease. This includes:</p>
<ul>
<li>
<p><strong>Parameter Sweeps</strong>: Efficiently explore hyperparameter spaces across multiple nodes and GPUs.</p>
</li>
<li>
<p><strong>Scalable Tournaments</strong>: Run extensive multi-agent tournaments across distributed computing environments.</p>
</li>
</ul>
<p>These capabilities make Game Reasoning Arena a powerful tool for conducting rigorous and scalable academic research.</p>
<h2><a id="monitoring-and-visualization-via-tensorboard" class="anchor" href="#monitoring-and-visualization-via-tensorboard" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Monitoring and Visualization via Tensorboard</h2>
<p>Game Reasoning Arena includes native TensorBoard integration for experiment monitoring:</p>
<ul>
<li><strong>Real-time Metrics</strong>: Monitor win rates, reward progressions, and performance trends during gameplay</li>
<li><strong>Multi-Agent Comparison</strong>: Side-by-side visualization of different LLM strategies</li>
<li><strong>Performance Evolution</strong>: Track how agents perform over multiple episodes</li>
<li><strong>Strategy Analysis</strong>: Identify successful patterns and strategic failures</li>
</ul>
<h2><a id="extensibility-and-customization" class="anchor" href="#extensibility-and-customization" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Extensibility and Customization</h2>
<p>Game Reasoning Arena's modular architecture facilitates easy extension:</p>
<ul>
<li>Adding new games</li>
<li>Adding new LLM providers</li>
<li>Adding custom policies such as reinforcement learning policies</li>
</ul>
<h3><a id="analysis-pipeline-extension" class="anchor" href="#analysis-pipeline-extension" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Analysis Pipeline Extension</h3>
<p>The reasoning traces database and analysis pipeline are designed to be extensible, allowing researchers to develop custom analysis tools for specific research questions.</p>
<h2><a id="research-applications-and-findings" class="anchor" href="#research-applications-and-findings" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Research Applications and Findings</h2>
<p>Game Reasoning Arena has already enabled several interesting research observations:</p>
<ul>
<li><strong>Strategic Specialization</strong>: Certain LLMs demonstrate strong tactical play but struggle with long-term strategic planning</li>
<li><strong>Reasoning Diversity</strong>: Different models exhibit distinct strategic approaches and decision-making patterns</li>
<li><strong>Cross-Game Learning</strong>: Some strategic insights transfer between games, while others remain game-specific</li>
<li><strong>Opponent Modeling</strong>: Varying capabilities in predicting and countering opponent strategies</li>
<li><strong>Decision Consistency</strong>: Different levels of adherence to strategic principles under pressure</li>
</ul>
<p>These findings contribute to our understanding of LLM capabilities and limitations in decision-making scenarios that parallel real-world strategic challenges.</p>
<h2><a id="example-results" class="anchor" href="#example-results" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Example Results</h2>
<p>Our analysis reveals fascinating insights into how different LLMs approach strategic thinking. Here are some key visualizations from our experiments:</p>
<hr>
<h3><a id="reasoning-pattern-distribution-across-models" class="anchor" href="#reasoning-pattern-distribution-across-models" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Reasoning Pattern Distribution Across Models</h3>
<p><img src="/images/blog/game_reasoning_arena/0_reasoning_types.png" alt="Reasoning Types Overview">
<em>Distribution of reasoning types across all LLM models and games, showing distinct strategic thinking patterns.</em></p>
<p><img src="/images/blog/game_reasoning_arena/radar_comparison_llm_litellm_groq_llama3_70b_8192.png" alt="Reasoning Patterns Across Games – Llama3 70B">
<em>Radar plot showing the normalized distribution of reasoning types for each game played by Llama3 70B.</em></p>
<p>The radar chart reveals that Llama3 70B distributes its reasoning differently depending on the game context. For example, in <strong>Matching Pennies</strong> and <strong>Matrix PD</strong>, opponent modeling dominates, while <strong>Connect Four</strong> favors positional play. <strong>Rule-based reasoning</strong> emerges in <strong>Matrix RPS</strong>, showing that the model switches to more deterministic strategies when the game structure rewards fixed patterns.</p>
<hr>
<h3><a id="strategic-diversity-in-different-games" class="anchor" href="#strategic-diversity-in-different-games" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Strategic Diversity in Different Games</h3>
<p><img src="/images/blog/game_reasoning_arena/entropy_by_turn_all_agents_tic_tac_toe.png" alt="Entropy by Turn – Tic-Tac-Toe">
<em>Entropy of reasoning distribution per turn for all agents in Tic-Tac-Toe.</em></p>
<p>While the first plot compares average diversity per game, the second shows per-turn changes.</p>
<p>Entropy measures the diversity of reasoning patterns at each turn. Here we see  <strong>Llama3 8B</strong> spiking early in the game, suggesting exploration of different strategic avenues before quickly converging to a more fixed reasoning mode. In contrast, other models remain static, indicating a more rigid approach from the start.</p>
<hr>
<h3><a id="evolution-of-reasoning-patterns-in-gameplay" class="anchor" href="#evolution-of-reasoning-patterns-in-gameplay" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Evolution of Reasoning Patterns in Gameplay</h3>
<p><img src="/images/blog/game_reasoning_arena/evolution_llm_litellm_groq_llama3_8b_8192_tic_tac_toe.png" alt="Reasoning Category Evolution – Llama3 8B Tic-Tac-Toe">
<em>Proportion of reasoning categories as the game progresses. How Llama3 8B's reasoning patterns evolve during tic-tac-toe gameplay - notice the shift from positional to blocking strategies.</em></p>
<p><strong>Llama3 8B</strong> starts with opponent modeling, shifts to positional play, then locks into blocking for the rest of the match. This suggests a defensive bias once the mid-game begins, perhaps prioritizing risk avoidance over creating winning opportunities.</p>
<hr>
<h3><a id="model-specific-strategic-preferences" class="anchor" href="#model-specific-strategic-preferences" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Model-Specific Strategic Preferences</h3>
<p><img src="/images/blog/game_reasoning_arena/reasoning_pie_llm_litellm_groq_llama3_8b_8192.png" alt="Llama3 8B Reasoning Distribution">
<em>Llama3 8B shows strong preference for positional reasoning and blocking strategies.</em></p>
<p><img src="/images/blog/game_reasoning_arena/reasoning_pie_llm_litellm_groq_llama3_70b_8192.png" alt="Llama3 70B Reasoning Distribution">
<em>Llama3 70B demonstrates more diverse reasoning patterns with increased opponent modeling.</em></p>
<p><img src="/images/blog/game_reasoning_arena/reasoning_by_game_llm_litellm_groq_llama3_8b_8192.png" alt="Reasoning by Game – Llama3 8B">
<em>Reasoning type proportions for Llama3 8B across all games.</em></p>
<p><img src="/images/blog/game_reasoning_arena/reasoning_by_game_llm_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo.png" alt="Reasoning by Game – Llama3.1 8B Instruct">
<em>Reasoning type breakdown for Llama3.1 8B Instruct.</em></p>
<p>While Llama3 70B displays adaptive patterns across games, Llama3.1 8B Instruct often commits to a single reasoning mode for an entire match (e.g., Winning Logic in Connect Four, Opponent Modeling elsewhere).</p>
<hr>
<h3><a id="aggregated-reasoning-proportions-with-labels" class="anchor" href="#aggregated-reasoning-proportions-with-labels" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Aggregated Reasoning Proportions with Labels</h3>
<p><img src="/images/blog/game_reasoning_arena/reasoning_stacked_llm_litellm_groq_llama3_8b_8192.png" alt="Stacked Reasoning Distribution – Llama3 8B">
<em>Stacked bar chart of reasoning proportions per game, with percentage labels.</em></p>
<p>This view makes it clear that some games (like Tic-Tac-Toe) are dominated by one reasoning type, while others (like Connect Four, Kuhn Poker) exhibit a more balanced mix.</p>
<hr>
<h3><a id="strategic-position-analysis" class="anchor" href="#strategic-position-analysis" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Strategic Position Analysis</h3>
<p><img src="/images/blog/game_reasoning_arena/evolution_heatmap_llm_litellm_groq_llama3_8b_8192_tic_tac_toe.png" alt="Tic-Tac-Toe Heatmap Llama3 8B">
<em>Llama3 8B's positional preferences in tic-tac-toe - sophisticated spatial reasoning with balanced positional strategy.</em></p>
<hr>
<p>These visualizations demonstrate how Game Reasoning Arena enables researchers to:</p>
<ul>
<li><strong>Compare strategic sophistication</strong> between model sizes (8B vs 70B parameters)</li>
<li><strong>Identify reasoning pattern evolution</strong> during gameplay</li>
<li><strong>Analyze positional and tactical preferences</strong> across different games</li>
<li><strong>Quantify strategic diversity</strong> and decision-making consistency</li>
</ul>
<p>Different LLMs not only vary in their strategic preferences but also in how flexible (or rigid) those preferences are over time. The data reveals that larger models (70B) tend to exhibit more adaptive, context-sensitive reasoning, while smaller models (8B) often commit early to a strategy and maintain it throughout the match.</p>
<hr>
<h3><a id="citation" class="anchor" href="#citation" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Citation</h3>
<pre><code class="language-bibtex">@article{cipolina-kun2025game_reasoning_arena,
    title={Game Reasoning Arena: A Framework and Benchmark for Assessing Reasoning Capabilites of Large Language Models via Game Play},
    author={Lucia Cipolina-Kun and Marianna Nezhurina and Jenia Jitsev},
    year={2025},
    journal={arXiv},
    url={https://arxiv.org/abs/2}
}
</code></pre>
<h3><a id="community" class="anchor" href="#community" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Community</h3>
<ul>
<li><strong>Issues</strong>: Bug reports and feature requests via GitHub</li>
<li><strong>Contributions</strong>: New games, agents, and analysis tools are welcome</li>
<li><strong>Research Collaboration</strong>: Contact the authors for academic partnerships</li>
</ul>
<h2><a id="acknowledgments" class="anchor" href="#acknowledgments" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Acknowledgments</h2>
<p>We acknowledge co-funding by EU from EuroHPC Joint Undertaking programm under grant no. 101182737 (MINERVA) and from Digital Europe Programme under grant no. 101195233 (openEuroLLM) as well as funding by the Federal Ministry of Education and Research of Germany (BMBF) under grant no. 01IS24085C (OPENHAFM), under the grant 16HPC117K (MINERVA) and under the grant no. 01IS22094B (WestAI - AI Service Center West).</p>
<p>This work was supported by the compute resources of <strong>Jülich Supercomputing Centre (JSC)</strong>. We further gratefully acknowledge storage resources on JUST granted and operated by JSC and supported by Helmholtz Data Federation (HDF).</p>
<p>We also would like to express gratitude to all the people who are working on making code, models and data publicly available, advancing community based research and making research more reproducible. Specifically, we would like to thank all the members of the <a href="https://discord.gg/BZqhreFazY">LAION Discord server</a> community and <a href="https://discord.gg/GsKh4mBVcv">Open-$\Psi$ (Open-Sci) Collective</a> for providing fruitful ground for scientific exchange and open-source development.</p>
<p>We further acknowledge the contributions of the <strong>OpenSpiel developers</strong> – Marc Lanctot, John Schultz, and Michael Kaisers – whose framework provides the foundation for strategic AI evaluation.</p>
<p>Game Reasoning Arena is released under a <strong>CC BY-NC 4.0 license</strong>, making it freely available for research and non-commercial applications.</p>
</div></div></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontmatter":{"title":"Game Reasoning Arena: Inside the Mind of AI: How LLMs Think, Strategize, and Compete in Real-Time","author":"Lucia Cipolina-Kun, Marianna Nezhurina, Jenia Jitsev","date":"Aug 4 2025","previewImg":"/images/blog/game_reasoning_arena/0_blog_logo.png"},"content":"\n### Access\n- **Repository**: [https://github.com/SLAMPAI/game_reasoning_arena](https://github.com/SLAMPAI/game_reasoning_arena)\n- **Documentation**: Complete installation, usage, and extension guides available at [Game Reasoning Arena Documentation](https://board-game-arena.readthedocs.io/en/latest/index.html)\n\n\nWhat happens when we peek inside an AI's mind while it's making strategic decisions? For the first time, we can watch Large Language Models think in real-time as they compete, strategize, and adapt in dynamic game environments. Our Game Reasoning Arena doesn't just test what AI can do—it reveals *how* AI thinks, capturing every reasoning step as models battle each other in strategic gameplay.\n\n*The first platform to expose AI's strategic DNA in action*\n\n\nGame Reasoning Arena is a research platform where Large Language Models battle in board games against other LLMs, humans, or random bots—while exposing every step of their strategic reasoning. Built on Google’s OpenSpiel with a modular, Gymnasium-style interface, it supports custom games, agents, and analysis tools. Scalable Ray-based parallelization powers large tournaments, making it a fast, flexible testbed for studying how AI thinks under competition and uncertainty.\n\n---\n### Quick start with Google Colab\n\n**[Click here to try Game Reasoning Arena in our Colab now!](https://github.com/SLAMPAI/game_reasoning_arena/blob/main/colabs/game_reasoning_arena.ipynb)**\n---\n\n\n\n## Why Strategic Games Matter for AI Evaluation\n\nStrategic games offer unique evaluation opportunities that traditional benchmarks cannot provide: genuine decision-making under uncertainty. When an LLM plays Tic-Tac-Toe, Connect Four, or Poker, it must:\n\n- Analyze complex game states with multiple possible outcomes\n- Reason about opponent behavior and predict future moves\n- Balance short-term tactics with long-term strategic goals\n- Handle incomplete information and make decisions under pressure\n- Adapt strategies based on opponent responses\n\nThis creates an ideal testing environment for evaluating the strategic reasoning capabilities that will be crucial as LLMs become more integrated into decision-making roles across industries.\n\n## Key Features of Game Reasoning Arena\n\n### Multi-Agent Testing Framework\n\nGame Reasoning Arena supports comprehensive competitive scenarios:\n\n- **LLM vs Random**: Establish baseline performance against unpredictable opponents.\n- **LLM vs LLM**: Direct strategic competitions between different language models.\n- **Self-Play**: Enable LLMs to develop strategies by playing against themselves.\n- **Cross-Provider Tournaments**: Compare models from different providers within the same game.\n\n### Diverse Game Library\n\nThe framework includes a carefully selected set of games that test different aspects of strategic thinking:\n\n- **`tic_tac_toe`** - Classic spatial reasoning and tactical planning\n- **`connect_four`** - Long-term strategic positioning and pattern recognition\n- **`kuhn_poker`** - Hidden information, bluffing, and probabilistic reasoning\n- **`prisoners_dilemma`** - Cooperation versus competition dynamics\n- **`matching_pennies`** - Zero-sum game theory and randomization strategies\n- **`matrix_rps`** - Rock-paper-scissors with matrix representation\n- **`hex`** -  Complex pathfinding and connection strategies on a hexagonal grid\n- **`chess`** - Deep combinatorial reasoning, multi-phase planning, and tactical foresight\n\nEach game challenges LLMs in unique ways, from spatial reasoning to probabilistic thinking to social dynamics.\n\n### Flexible Inference Architecture\n\nOne of Game Reasoning Arena's key strengths is its dual-backend architecture:\n\n**LiteLLM Backend** - Access to over 100 language models through APIs:\n- **OpenAI**: GPT-3.5, GPT-4, GPT-4 Turbo\n- **Anthropic**: Claude 3, Claude 3.5 Sonnet\n- **Google**: Gemini Pro, Gemma models\n- **Groq**: Ultra-fast Llama 3 and Gemma inference\n- **Together AI**: Llama 3.1, Mixtral, Code Llama\n- **Additional providers**: Supporting over 90 other model providers for comprehensive comparison\n\n**vLLM Backend** - Local GPU inference for:\n- Complete control over model parameters\n- Privacy-sensitive research applications\n- Custom fine-tuned models\n- Cost-effective large-scale experiments\n\nIt also supports Hugging Face backends.\n\nThe system allows researchers to mix different backends within the same experiment, enabling direct comparison between proprietary and open-source models, or between API-based and locally-hosted implementations.\n\n## Reasoning Traces: Understanding AI Decision-Making\n\nA particularly valuable feature of Game Reasoning Arena is its automatic reasoning traces capability. This functionality captures not only what move an LLM made, but also the reasoning behind that decision.\n\n### Data Collection\n\nFor every move made by an LLM agent, Game Reasoning Arena automatically records:\n\n- **Board State**: The exact game position when the decision was made\n- **Agent Reasoning**: The LLM's complete thought process and explanation\n- **Action Context**: The chosen move with full metadata and timing\n- **Decision Patterns**: Categorized reasoning types and strategic approaches\n\n### Example Reasoning Trace\n\nHere is an example of the reasoning traces captured during gameplay:\n\n```\nReasoning Trace #1\n----------------------------------------\nGame: connect_four\nEpisode: 3, Turn: 5\nAgent: litellm_groq/llama3-8b-8192\nAction Chosen: 3\n\nBoard State at Decision Time:\n     . . . . . . .\n     . . . . . . .\n     . . x . . . .\n     . o x . . . .\n     o x o . . . .\n     x o x . . . .\n\nAgent's Reasoning:\n     I need to block the opponent's potential win. They have\n     two pieces in column 2 and if I don't act now, they\n     could get three in a row vertically. Playing column 3\n     also gives me a chance to build my own threat\n     horizontally while staying defensive.\n\nTimestamp: 2025-08-04 14:23:17\n```\n\n### Analysis Tools\n\nGame Reasoning Arena includes comprehensive analysis capabilities for reasoning traces:\n\n- **Reasoning Categorization**: Automatically classifies thinking patterns (Positional, Blocking, Winning Logic, Opponent Modeling, etc.)\n- **Pattern Visualization**: Word clouds showing common reasoning terms, pie charts of strategy types\n- **Performance Heatmaps**: Visual maps showing move preferences and strategic tendencies\n- **Statistical Analysis**: Quantitative measures of decision-making patterns\n\nThis provides researchers with tools for understanding how different LLMs approach strategic problems, what reasoning patterns correlate with success, and where current models have strategic limitations.\n\n## Distributed Computing and Scalability\n\nGame Reasoning Arena supports large-scale experiments through distributed computing capabilities:\n\n### Ray Integration\n\n- **Parallel Episodes**: Execute multiple games simultaneously across different cores\n- **Multi-Game Tournaments**: Run complex tournament brackets in parallel\n- **Distributed LLM Inference**: Efficiently batch and distribute model calls\n- **Real-time Monitoring**: Ray dashboard for live experiment tracking\n\n### SLURM Cluster Support\n\nGame Reasoning Arena integrates seamlessly with SLURM clusters, enabling researchers to conduct large-scale academic experiments with ease. This includes:\n\n- **Parameter Sweeps**: Efficiently explore hyperparameter spaces across multiple nodes and GPUs.\n\n- **Scalable Tournaments**: Run extensive multi-agent tournaments across distributed computing environments.\n\n\nThese capabilities make Game Reasoning Arena a powerful tool for conducting rigorous and scalable academic research.\n\n## Monitoring and Visualization via Tensorboard\n\nGame Reasoning Arena includes native TensorBoard integration for experiment monitoring:\n\n- **Real-time Metrics**: Monitor win rates, reward progressions, and performance trends during gameplay\n- **Multi-Agent Comparison**: Side-by-side visualization of different LLM strategies\n- **Performance Evolution**: Track how agents perform over multiple episodes\n- **Strategy Analysis**: Identify successful patterns and strategic failures\n\n\n## Extensibility and Customization\n\nGame Reasoning Arena's modular architecture facilitates easy extension:\n\n* Adding new games\n* Adding new LLM providers\n* Adding custom policies such as reinforcement learning policies\n\n\n### Analysis Pipeline Extension\nThe reasoning traces database and analysis pipeline are designed to be extensible, allowing researchers to develop custom analysis tools for specific research questions.\n\n## Research Applications and Findings\n\nGame Reasoning Arena has already enabled several interesting research observations:\n\n- **Strategic Specialization**: Certain LLMs demonstrate strong tactical play but struggle with long-term strategic planning\n- **Reasoning Diversity**: Different models exhibit distinct strategic approaches and decision-making patterns\n- **Cross-Game Learning**: Some strategic insights transfer between games, while others remain game-specific\n- **Opponent Modeling**: Varying capabilities in predicting and countering opponent strategies\n- **Decision Consistency**: Different levels of adherence to strategic principles under pressure\n\nThese findings contribute to our understanding of LLM capabilities and limitations in decision-making scenarios that parallel real-world strategic challenges.\n\n\n## Example Results\n\nOur analysis reveals fascinating insights into how different LLMs approach strategic thinking. Here are some key visualizations from our experiments:\n\n---\n\n### Reasoning Pattern Distribution Across Models\n\n![Reasoning Types Overview](/images/blog/game_reasoning_arena/0_reasoning_types.png)\n*Distribution of reasoning types across all LLM models and games, showing distinct strategic thinking patterns.*\n\n![Reasoning Patterns Across Games – Llama3 70B](/images/blog/game_reasoning_arena/radar_comparison_llm_litellm_groq_llama3_70b_8192.png)\n*Radar plot showing the normalized distribution of reasoning types for each game played by Llama3 70B.*\n\n\nThe radar chart reveals that Llama3 70B distributes its reasoning differently depending on the game context. For example, in **Matching Pennies** and **Matrix PD**, opponent modeling dominates, while **Connect Four** favors positional play. **Rule-based reasoning** emerges in **Matrix RPS**, showing that the model switches to more deterministic strategies when the game structure rewards fixed patterns.\n\n---\n\n### Strategic Diversity in Different Games\n\n\n![Entropy by Turn – Tic-Tac-Toe](/images/blog/game_reasoning_arena/entropy_by_turn_all_agents_tic_tac_toe.png)\n*Entropy of reasoning distribution per turn for all agents in Tic-Tac-Toe.*\n\nWhile the first plot compares average diversity per game, the second shows per-turn changes.\n\nEntropy measures the diversity of reasoning patterns at each turn. Here we see  **Llama3 8B** spiking early in the game, suggesting exploration of different strategic avenues before quickly converging to a more fixed reasoning mode. In contrast, other models remain static, indicating a more rigid approach from the start.\n\n---\n\n### Evolution of Reasoning Patterns in Gameplay\n\n![Reasoning Category Evolution – Llama3 8B Tic-Tac-Toe](/images/blog/game_reasoning_arena/evolution_llm_litellm_groq_llama3_8b_8192_tic_tac_toe.png)\n*Proportion of reasoning categories as the game progresses. How Llama3 8B's reasoning patterns evolve during tic-tac-toe gameplay - notice the shift from positional to blocking strategies.*\n\n**Llama3 8B** starts with opponent modeling, shifts to positional play, then locks into blocking for the rest of the match. This suggests a defensive bias once the mid-game begins, perhaps prioritizing risk avoidance over creating winning opportunities.\n\n---\n\n### Model-Specific Strategic Preferences\n\n![Llama3 8B Reasoning Distribution](/images/blog/game_reasoning_arena/reasoning_pie_llm_litellm_groq_llama3_8b_8192.png)\n*Llama3 8B shows strong preference for positional reasoning and blocking strategies.*\n\n![Llama3 70B Reasoning Distribution](/images/blog/game_reasoning_arena/reasoning_pie_llm_litellm_groq_llama3_70b_8192.png)\n*Llama3 70B demonstrates more diverse reasoning patterns with increased opponent modeling.*\n\n![Reasoning by Game – Llama3 8B](/images/blog/game_reasoning_arena/reasoning_by_game_llm_litellm_groq_llama3_8b_8192.png)\n*Reasoning type proportions for Llama3 8B across all games.*\n\n![Reasoning by Game – Llama3.1 8B Instruct](/images/blog/game_reasoning_arena/reasoning_by_game_llm_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo.png)\n*Reasoning type breakdown for Llama3.1 8B Instruct.*\n\nWhile Llama3 70B displays adaptive patterns across games, Llama3.1 8B Instruct often commits to a single reasoning mode for an entire match (e.g., Winning Logic in Connect Four, Opponent Modeling elsewhere).\n\n---\n\n### Aggregated Reasoning Proportions with Labels\n\n![Stacked Reasoning Distribution – Llama3 8B](/images/blog/game_reasoning_arena/reasoning_stacked_llm_litellm_groq_llama3_8b_8192.png)\n*Stacked bar chart of reasoning proportions per game, with percentage labels.*\n\nThis view makes it clear that some games (like Tic-Tac-Toe) are dominated by one reasoning type, while others (like Connect Four, Kuhn Poker) exhibit a more balanced mix.\n\n---\n\n### Strategic Position Analysis\n\n![Tic-Tac-Toe Heatmap Llama3 8B](/images/blog/game_reasoning_arena/evolution_heatmap_llm_litellm_groq_llama3_8b_8192_tic_tac_toe.png)\n*Llama3 8B's positional preferences in tic-tac-toe - sophisticated spatial reasoning with balanced positional strategy.*\n\n\n---\n\nThese visualizations demonstrate how Game Reasoning Arena enables researchers to:\n\n- **Compare strategic sophistication** between model sizes (8B vs 70B parameters)\n- **Identify reasoning pattern evolution** during gameplay\n- **Analyze positional and tactical preferences** across different games\n- **Quantify strategic diversity** and decision-making consistency\n\nDifferent LLMs not only vary in their strategic preferences but also in how flexible (or rigid) those preferences are over time. The data reveals that larger models (70B) tend to exhibit more adaptive, context-sensitive reasoning, while smaller models (8B) often commit early to a strategy and maintain it throughout the match.\n\n___\n\n### Citation\n```bibtex\n@article{cipolina-kun2025game_reasoning_arena,\n    title={Game Reasoning Arena: A Framework and Benchmark for Assessing Reasoning Capabilites of Large Language Models via Game Play},\n    author={Lucia Cipolina-Kun and Marianna Nezhurina and Jenia Jitsev},\n    year={2025},\n    journal={arXiv},\n    url={https://arxiv.org/abs/2}\n}\n```\n\n### Community\n- **Issues**: Bug reports and feature requests via GitHub\n- **Contributions**: New games, agents, and analysis tools are welcome\n- **Research Collaboration**: Contact the authors for academic partnerships\n\n## Acknowledgments\n\nWe acknowledge co-funding by EU from EuroHPC Joint Undertaking programm under grant no. 101182737 (MINERVA) and from Digital Europe Programme under grant no. 101195233 (openEuroLLM) as well as funding by the Federal Ministry of Education and Research of Germany (BMBF) under grant no. 01IS24085C (OPENHAFM), under the grant 16HPC117K (MINERVA) and under the grant no. 01IS22094B (WestAI - AI Service Center West).\n\n\nThis work was supported by the compute resources of **Jülich Supercomputing Centre (JSC)**. We further gratefully acknowledge storage resources on JUST granted and operated by JSC and supported by Helmholtz Data Federation (HDF).\n\nWe also would like to express gratitude to all the people who are working on making code, models and data publicly available, advancing community based research and making research more reproducible. Specifically, we would like to thank all the members of the [LAION Discord server](https://discord.gg/BZqhreFazY) community and [Open-$\\Psi$ (Open-Sci) Collective](https://discord.gg/GsKh4mBVcv) for providing fruitful ground for scientific exchange and open-source development.\n\nWe further acknowledge the contributions of the **OpenSpiel developers** – Marc Lanctot, John Schultz, and Michael Kaisers – whose framework provides the foundation for strategic AI evaluation.\n\nGame Reasoning Arena is released under a **CC BY-NC 4.0 license**, making it freely available for research and non-commercial applications.\n","slug":"board_game_arena_blog_post"},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"board_game_arena_blog_post"},"buildId":"RUv6f7SBqEtJtqqMGa8sZ","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>