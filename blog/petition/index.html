<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><title>Petition for keeping up the progress tempo on AI research while securing its transparency and safety. | LAION</title><meta name="title" content="Petition for keeping up the progress tempo on AI research while securing its transparency and safety. | LAION"/><meta property="og:title" content="Petition for keeping up the progress tempo on AI research while securing its transparency and safety. | LAION"/><meta name="twitter:title" content="Petition for keeping up the progress tempo on AI research while securing its transparency and safety. | LAION"/><meta name="description" content="&lt;p&gt;&lt;a href=&quot;https://www.openpetition.eu/petition/online/securing-our-digital-future-a-cern-for-open-source-large-scale-ai-research-and-its-safety&quot;&gt;LINK TO OU..."/><meta property="og:description" content="&lt;p&gt;&lt;a href=&quot;https://www.openpetition.eu/petition/online/securing-our-digital-future-a-cern-for-open-source-large-scale-ai-research-and-its-safety&quot;&gt;LINK TO OU..."/><meta name="twitter:description" content="&lt;p&gt;&lt;a href=&quot;https://www.openpetition.eu/petition/online/securing-our-digital-future-a-cern-for-open-source-large-scale-ai-research-and-its-safety&quot;&gt;LINK TO OU..."/><meta property="og:image" content="https://laion.ai/images/blog/laion-black.png"/><meta name="twitter:image" content="https://laion.ai/images/blog/laion-black.png"/><meta name="twitter:image:alt" content="The text: LAION. Large-scale Artificial Intelligence Open Network, TRULY OPEN AI. 100% NON-PROFIT. 100% FREE."/><meta property="og:type" content="website"/><meta property="og:url" content="https://laion.ai/blog/petition"/><meta name="twitter:url" content="https://laion.ai/blog/petition"/><meta name="twitter:card" content="summary_large_image"/><meta name="viewport" content="initial-scale=1.0, width=device-width"/><meta name="theme-color" content="#1D374E"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon.png"/><link rel="icon" href="/favicon.svg" type="image/svg+xml"/><link rel="preload" href="/fonts/DinishCondensed-Bold.woff" as="font" type="font/woff"/><link rel="preload" href="/fonts/DinishCondensed-Bold.woff2" as="font" type="font/woff2"/><link rel="preload" href="/fonts/Dinish-Regular.woff" as="font" type="font/woff"/><link rel="preload" href="/fonts/Dinish-Regular.woff2" as="font" type="font/woff2"/><link rel="preload" href="/fonts/Dinish-Italic.woff" as="font" type="font/woff"/><link rel="preload" href="/fonts/Dinish-Italic.woff2" as="font" type="font/woff2"/><meta name="next-head-count" content="25"/><link rel="stylesheet" href="/fonts/load.css"/><link rel="preload" href="/_next/static/css/6182a1940c49bb84.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6182a1940c49bb84.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-5752944655d749a0.js" defer=""></script><script src="/_next/static/chunks/framework-a87821de553db91d.js" defer=""></script><script src="/_next/static/chunks/main-6a269cfcb9446759.js" defer=""></script><script src="/_next/static/chunks/pages/_app-e4898286327de07c.js" defer=""></script><script src="/_next/static/chunks/286-48ebbaba72d91976.js" defer=""></script><script src="/_next/static/chunks/807-a4eae1dfa8bfbe9f.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-891d88d46bc1d783.js" defer=""></script><script src="/_next/static/D9SDo1RXu8sdnbiUYMYlL/_buildManifest.js" defer=""></script><script src="/_next/static/D9SDo1RXu8sdnbiUYMYlL/_ssgManifest.js" defer=""></script><script src="/_next/static/D9SDo1RXu8sdnbiUYMYlL/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><div class="w-screen full-container flex-col md:flex-row flex "><div class="md:basis-1/5 "><div class="navbar fixed w-full flex md:flex-col px-4 md:px-6 py-2 md:py-6 md:pb-7 z-30 bg-sky text-paper md:h-full items-center justify-between md:static md:w-auto md:bg-paper md:text-sky md:max-h-screen md:justify-between child:pl-2 child:md:pl-0 child:text-lg "><div><p class="text-4xl md:text-7xl cursor-pointer font-bold pl-0 md:pb-3">LAION</p><div class="md:flex child:pl-3 md:text-xl child:md:pl-1 child:md:pt-2 hidden md:flex-col child:brightness-100 child:transition"><a href="/projects/">Projects</a><a href="/team/">Team</a><a href="/blog/">Blog</a><a href="/notes/">Notes</a><a href="/about/">About</a><a href="/faq/">FAQ</a><a href="/privacy-policy/">Privacy Policy</a><a href="/dataset-requests/">Dataset Requests</a><a href="/impressum/">Impressum</a></div></div><div class="child:mr-3 -ml-0.5 child:w-8 child:brightness-100 child:transition hidden md:flex"><a href="mailto:contact@laion.ai" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg></a><a href="https://discord.com/invite/eq3cAMZtCC" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a><a href="https://github.com/LAION-AI/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></div><div class="md:hidden"><div><div class="bm-overlay" style="position:fixed;z-index:1000;width:100%;height:100%;background:rgba(0, 0, 0, 0.3);opacity:0;-moz-transform:translate3d(100%, 0, 0);-ms-transform:translate3d(100%, 0, 0);-o-transform:translate3d(100%, 0, 0);-webkit-transform:translate3d(100%, 0, 0);transform:translate3d(100%, 0, 0);transition:opacity 0.3s, transform 0s 0.3s;top:0px;left:0px"></div><div><div class="bm-burger-button" style="z-index:1000;position:fixed;width:1.2em;height:1.0em;right:1.2rem;top:1em"><button type="button" id="react-burger-menu-btn" style="position:absolute;left:0;top:0;z-index:1;width:100%;height:100%;margin:0;padding:0;border:none;font-size:0;background:transparent;cursor:pointer">Open Menu</button><span><span class="bm-burger-bars" style="position:absolute;height:20%;left:0;right:0;top:0%;opacity:1;background:#fff"></span><span class="bm-burger-bars" style="position:absolute;height:20%;left:0;right:0;top:40%;opacity:1;background:#fff"></span><span class="bm-burger-bars" style="position:absolute;height:20%;left:0;right:0;top:80%;opacity:1;background:#fff"></span></span></div></div><div id="" class="bm-menu-wrap" style="position:fixed;right:0;z-index:1100;width:300px;height:100%;-moz-transform:translate3d(100%, 0, 0);-ms-transform:translate3d(100%, 0, 0);-o-transform:translate3d(100%, 0, 0);-webkit-transform:translate3d(100%, 0, 0);transform:translate3d(100%, 0, 0);transition:all 0.5s;top:0px" aria-hidden="true"><div class="bm-menu" style="height:100%;box-sizing:border-box;overflow:auto;background:#1D374E;padding:2.5em 1.5em 0"><nav class="bm-item-list" style="height:100%;color:#fff;padding:0.8em"><div class="bm-item" style="display:inline-block" tabindex="-1"><div class="child:pb-2 child:child:text-2xl"><p><a href="/projects/">Projects</a></p><p><a href="/team/">Team</a></p><p><a href="/blog/">Blog</a></p><p><a href="/about/">About</a></p><p><a href="/faq/">FAQ</a></p><p><a href="/privacy-policy/">Privacy Policy</a></p><p><a href="/dataset-requests/">Dataset Requests</a></p><p><a href="/impressum/">Impressum</a></p></div><div class="child:mr-3 pt-4 child:w-8 child:brightness-100 hover:child:brightness-90 child:transition flex"><a href="mailto:contact@laion.ai" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg></a><a href="https://discord.com/invite/eq3cAMZtCC" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a><a href="https://github.com/LAION-AI/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></div></div></nav></div><div><div class="bm-cross-button" style="position:absolute;width:24px;height:24px;right:8px;top:8px"><button type="button" id="react-burger-cross-btn" style="position:absolute;left:0;top:0;z-index:1;width:100%;height:100%;margin:0;padding:0;border:none;font-size:0;background:transparent;cursor:pointer" tabindex="-1">Close Menu</button><span style="position:absolute;top:6px;right:14px"><span class="bm-cross" style="position:absolute;width:3px;height:14px;transform:rotate(45deg);background:#fff"></span><span class="bm-cross" style="position:absolute;width:3px;height:14px;transform:rotate(-45deg);background:#fff"></span></span></div></div></div></div></div></div></div><div id="content" class="md:overflow-y-scroll md:max-h-screen md:z-50 md:shadow-lg shadow-neutral-600/70 text-paper grow md:grow-0 md:basis-4/5 flex child:grow flex-col "><div class="" style="opacity:0"><div class="w-full flex justify-center py-5 pt-16 md:pt-5"><div class="container px-5" lang="en"><h1 lang="en" style="hyphens:auto" class="text-8xl md:text-8xl w-full font-bold title-flow break-words">PETITION FOR KEEPING UP THE PROGRESS TEMPO ON AI RESEARCH WHILE SECURING ITS TRANSPARENCY AND SAFETY.</h1><p class="text-2xl pb-2">by: <!-- -->LAION.ai<!-- -->,<!-- --> <!-- -->29 Mar, 2023<!-- --></p><hr/><div class="pt-2 article"><p><a href="https://www.openpetition.eu/petition/online/securing-our-digital-future-a-cern-for-open-source-large-scale-ai-research-and-its-safety">LINK TO OUR PETITION</a></p>
<p><em>Authors: Christoph Schuhmann, Huu Nguyen, Robert Kaczmarczyk, Jenia Jitsev &amp; LAION community</em></p>
<h2><a id="securing-our-digital-future-calling-for-cern-like-international-organization-to-transparently-coordinate-and-progress-on-large-scale-ai-research-and-its-safety" class="anchor" href="#securing-our-digital-future-calling-for-cern-like-international-organization-to-transparently-coordinate-and-progress-on-large-scale-ai-research-and-its-safety" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Securing Our Digital Future: Calling for CERN like international organization to transparently coordinate and progress on large-scale AI research and its safety</h2>
<p>In an era of unparalleled technological advancements, humanity stands on the precipice of a new epoch characterized by the profound influence of artificial intelligence (AI) and its foundational models, such as GPT-4. The potential applications of these technologies are vast, spanning scientific research, education, governance, and small and medium-sized enterprises. To harness their full potential as tools for societal betterment, it is vital to democratize research on and access to them, lest we face severe repercussions for our collective future.</p>
<h3><a id="dominance-of-few-large-corporations-in-ai-development" class="anchor" href="#dominance-of-few-large-corporations-in-ai-development" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Dominance of few large corporations in AI development</h3>
<p>Increasingly, we are witnessing the emergence of a system wherein educational institutions, government agencies, and entire nations become dependent on the AI technology of a select few large corporations that operate with little transparency or public accountability. To secure our society's technological independence, foster innovation, and safeguard the democratic principles that underpin our way of life, we must act now.
We call upon the global community, particularly the European Union, the United States, the United Kingdom, Canada, Australia and other willing countries, to collaborate on a monumental initiative: the establishment of an international, publicly funded, open-source supercomputing research facility. This facility, analogous to the CERN project in scale and impact, should house a diverse array of machines equipped with at least 100,000 high-performance state-of-the-art accelerators (GPUs or ASICs), operated by experts from the machine learning and supercomputing research community and overseen by democratically elected institutions in the participating nations.</p>
<h3><a id="multimodal-future" class="anchor" href="#multimodal-future" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Multimodal future</h3>
<p>This ambitious endeavor will provide a platform for researchers and institutions worldwide to access and refine advanced AI models, such as GPT-4, harnessing their capabilities for the greater good. By making these models open source and incorporating multimodal data (audio, video, text, and program code), we can significantly enrich academic research, enhance transparency, and ensure data security. Furthermore, granting researchers access to the underlying training data will enable them to understand precisely what these models learn and how they function, an impossibility when restricted by APIs.
Additionally, the open-source nature of this project will promote safety and security research, allowing potential risks to be identified and addressed more rapidly and transparently by the academic community and open-source enthusiasts. This is a vital step in ensuring the safety and reliability of AI technologies as they become increasingly integrated into our lives.
The proposed facility should feature AI Safety research labs with well-defined security levels, akin to those used in biological research labs, where high-risk developments can be conducted by internationally renowned experts in the field, backed by regulations from democratic institutions. The results of such safety research should be transparent and available for the research community and society at large. These AI Safety research labs should be capable of designing timely countermeasures by studying developments that, according to broad scientific consensus, would predictably have a significant negative impact on our societies.</p>
<h3><a id="economic-impact" class="anchor" href="#economic-impact" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Economic impact</h3>
<p>Economically, this initiative will bring substantial benefits to small and medium-sized companies worldwide. By providing access to large foundation models, businesses can fine-tune these models for their specific use cases while retaining full control over the weights and data. This approach will also appeal to government institutions seeking transparency and control over AI applications in their operations.
The importance of this endeavor cannot be overstated. We must act swiftly to secure the independence of academia and government institutions from the technological monopoly of large corporations in AI research. Technologies like GPT-4 are too powerful and significant to be exclusively controlled by a select few.
In a world where machine learning expertise and resources for AI development become increasingly concentrated in large corporations, it is imperative that smaller enterprises, academic institutions, municipal administrations, and social organizations, as well as nation-states, assert their autonomy and refrain from relying solely on the benevolence of these powerful entities that are often driven by short-term profit interests and act without properly taking democratic institutions into their decision-making loop. We must take immediate and decisive action to secure the technological independence of our society, nurturing innovation while ensuring the safety of these developments and protecting the democratic principles that form the foundation of our way of life.</p>
<h3><a id="safety-measures" class="anchor" href="#safety-measures" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Safety measures</h3>
<p>The <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">recent proposition</a> of decelerating AI research as a means to ensure safety and progress presents an understandable but untenable  approach that will be detrimental to both objectives. Corporate or state actors will make advancements in the dark while simultaneously curtailing the public research community's ability to scrutinize the safety aspects of advanced AI systems thoroughly. Rather than impeding the momentum of public AI development, a more judicious and efficacious approach would be to foster a better-organized, transparent, safety-aware, and collaborative research environment. The establishment of transparent open-source AI safety labs tied to the international large-scale AI research facility as described above, which employ eligible AI safety experts, have corresponding publicly funded compute resources, and act according to regulations issued by democratic institutions, will cover the safety aspect without dampening progress. By embracing this cooperative framework, we can simultaneously ensure progress and the responsible development of AI technology, safeguarding the well-being of our society and the integrity of democratic values.</p>
<h3><a id="what-you-can-do" class="anchor" href="#what-you-can-do" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>What you can do</h3>
<p>We urge you to join us in this crucial campaign. Sign <a href="https://www.openpetition.eu/petition/online/securing-our-digital-future-a-cern-for-open-source-large-scale-ai-research-and-its-safety">this petition</a> and make your voice heard. Our collective digital future, the autonomy of our academic research, and the equilibrium of our global economy depend on our ability to act quickly and decisively.
Together, we can build a future where advanced AI technologies are accessible to all, and where innovation and progress are not constrained by the boundaries of a few powerful corporations. Let us seize this opportunity and build a brighter future for generations to come.</p>
</div></div></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontmatter":{"title":"Petition for keeping up the progress tempo on AI research while securing its transparency and safety.","author":"LAION.ai","date":"March 29 2023","previewImg":"/images/blog/laion-black.png"},"content":"\n[LINK TO OUR PETITION](https://www.openpetition.eu/petition/online/securing-our-digital-future-a-cern-for-open-source-large-scale-ai-research-and-its-safety)\n\n_Authors: Christoph Schuhmann, Huu Nguyen, Robert Kaczmarczyk, Jenia Jitsev \u0026 LAION community_\n\n## Securing Our Digital Future: Calling for CERN like international organization to transparently coordinate and progress on large-scale AI research and its safety\n\nIn an era of unparalleled technological advancements, humanity stands on the precipice of a new epoch characterized by the profound influence of artificial intelligence (AI) and its foundational models, such as GPT-4. The potential applications of these technologies are vast, spanning scientific research, education, governance, and small and medium-sized enterprises. To harness their full potential as tools for societal betterment, it is vital to democratize research on and access to them, lest we face severe repercussions for our collective future.\n\n### Dominance of few large corporations in AI development\n\nIncreasingly, we are witnessing the emergence of a system wherein educational institutions, government agencies, and entire nations become dependent on the AI technology of a select few large corporations that operate with little transparency or public accountability. To secure our society's technological independence, foster innovation, and safeguard the democratic principles that underpin our way of life, we must act now.\nWe call upon the global community, particularly the European Union, the United States, the United Kingdom, Canada, Australia and other willing countries, to collaborate on a monumental initiative: the establishment of an international, publicly funded, open-source supercomputing research facility. This facility, analogous to the CERN project in scale and impact, should house a diverse array of machines equipped with at least 100,000 high-performance state-of-the-art accelerators (GPUs or ASICs), operated by experts from the machine learning and supercomputing research community and overseen by democratically elected institutions in the participating nations.\n\n### Multimodal future\n\nThis ambitious endeavor will provide a platform for researchers and institutions worldwide to access and refine advanced AI models, such as GPT-4, harnessing their capabilities for the greater good. By making these models open source and incorporating multimodal data (audio, video, text, and program code), we can significantly enrich academic research, enhance transparency, and ensure data security. Furthermore, granting researchers access to the underlying training data will enable them to understand precisely what these models learn and how they function, an impossibility when restricted by APIs.\nAdditionally, the open-source nature of this project will promote safety and security research, allowing potential risks to be identified and addressed more rapidly and transparently by the academic community and open-source enthusiasts. This is a vital step in ensuring the safety and reliability of AI technologies as they become increasingly integrated into our lives.\nThe proposed facility should feature AI Safety research labs with well-defined security levels, akin to those used in biological research labs, where high-risk developments can be conducted by internationally renowned experts in the field, backed by regulations from democratic institutions. The results of such safety research should be transparent and available for the research community and society at large. These AI Safety research labs should be capable of designing timely countermeasures by studying developments that, according to broad scientific consensus, would predictably have a significant negative impact on our societies.\n\n### Economic impact\n\nEconomically, this initiative will bring substantial benefits to small and medium-sized companies worldwide. By providing access to large foundation models, businesses can fine-tune these models for their specific use cases while retaining full control over the weights and data. This approach will also appeal to government institutions seeking transparency and control over AI applications in their operations.\nThe importance of this endeavor cannot be overstated. We must act swiftly to secure the independence of academia and government institutions from the technological monopoly of large corporations in AI research. Technologies like GPT-4 are too powerful and significant to be exclusively controlled by a select few.\nIn a world where machine learning expertise and resources for AI development become increasingly concentrated in large corporations, it is imperative that smaller enterprises, academic institutions, municipal administrations, and social organizations, as well as nation-states, assert their autonomy and refrain from relying solely on the benevolence of these powerful entities that are often driven by short-term profit interests and act without properly taking democratic institutions into their decision-making loop. We must take immediate and decisive action to secure the technological independence of our society, nurturing innovation while ensuring the safety of these developments and protecting the democratic principles that form the foundation of our way of life.\n\n### Safety measures\n\nThe [recent proposition](https://futureoflife.org/open-letter/pause-giant-ai-experiments/) of decelerating AI research as a means to ensure safety and progress presents an understandable but untenable  approach that will be detrimental to both objectives. Corporate or state actors will make advancements in the dark while simultaneously curtailing the public research community's ability to scrutinize the safety aspects of advanced AI systems thoroughly. Rather than impeding the momentum of public AI development, a more judicious and efficacious approach would be to foster a better-organized, transparent, safety-aware, and collaborative research environment. The establishment of transparent open-source AI safety labs tied to the international large-scale AI research facility as described above, which employ eligible AI safety experts, have corresponding publicly funded compute resources, and act according to regulations issued by democratic institutions, will cover the safety aspect without dampening progress. By embracing this cooperative framework, we can simultaneously ensure progress and the responsible development of AI technology, safeguarding the well-being of our society and the integrity of democratic values.\n\n### What you can do\n\nWe urge you to join us in this crucial campaign. Sign [this petition](https://www.openpetition.eu/petition/online/securing-our-digital-future-a-cern-for-open-source-large-scale-ai-research-and-its-safety) and make your voice heard. Our collective digital future, the autonomy of our academic research, and the equilibrium of our global economy depend on our ability to act quickly and decisively.\nTogether, we can build a future where advanced AI technologies are accessible to all, and where innovation and progress are not constrained by the boundaries of a few powerful corporations. Let us seize this opportunity and build a brighter future for generations to come.\n","slug":"petition"},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"petition"},"buildId":"D9SDo1RXu8sdnbiUYMYlL","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>