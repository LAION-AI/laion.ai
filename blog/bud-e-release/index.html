<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><title>Introducing BUD-E 1.0: AI-Assisted Education for Everyone | LAION</title><meta name="title" content="Introducing BUD-E 1.0: AI-Assisted Education for Everyone | LAION"/><meta property="og:title" content="Introducing BUD-E 1.0: AI-Assisted Education for Everyone | LAION"/><meta name="twitter:title" content="Introducing BUD-E 1.0: AI-Assisted Education for Everyone | LAION"/><meta name="description" content="&lt;p&gt;Today marks a milestone in our journey towards democratizing education and empathy through technology. LAION e.V. &lt;em&gt;is thrilled to announce the release ..."/><meta property="og:description" content="&lt;p&gt;Today marks a milestone in our journey towards democratizing education and empathy through technology. LAION e.V. &lt;em&gt;is thrilled to announce the release ..."/><meta name="twitter:description" content="&lt;p&gt;Today marks a milestone in our journey towards democratizing education and empathy through technology. LAION e.V. &lt;em&gt;is thrilled to announce the release ..."/><meta property="og:image" content="https://laion.ai/images/blog/bud-e-1.0.png"/><meta name="twitter:image" content="https://laion.ai/images/blog/bud-e-1.0.png"/><meta name="twitter:image:alt" content="The text: LAION. Large-scale Artificial Intelligence Open Network, TRULY OPEN AI. 100% NON-PROFIT. 100% FREE."/><meta property="og:type" content="website"/><meta property="og:url" content="https://laion.ai/blog/bud-e-release"/><meta name="twitter:url" content="https://laion.ai/blog/bud-e-release"/><meta name="twitter:card" content="summary_large_image"/><meta name="viewport" content="initial-scale=1.0, width=device-width"/><meta name="theme-color" content="#1D374E"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon.png"/><link rel="icon" href="/favicon.svg" type="image/svg+xml"/><link rel="preload" href="/fonts/DinishCondensed-Bold.woff" as="font" type="font/woff" crossorigin="true"/><link rel="preload" href="/fonts/DinishCondensed-Bold.woff2" as="font" type="font/woff2" crossorigin="true"/><link rel="preload" href="/fonts/Dinish-Regular.woff" as="font" type="font/woff" crossorigin="true"/><link rel="preload" href="/fonts/Dinish-Regular.woff2" as="font" type="font/woff2" crossorigin="true"/><link rel="preload" href="/fonts/Dinish-Italic.woff" as="font" type="font/woff" crossorigin="true"/><link rel="preload" href="/fonts/Dinish-Italic.woff2" as="font" type="font/woff2" crossorigin="true"/><meta name="next-head-count" content="25"/><link rel="stylesheet" href="/fonts/load.css"/><link rel="preload" href="/_next/static/css/5357c8cce67e7f29.css" as="style"/><link rel="stylesheet" href="/_next/static/css/5357c8cce67e7f29.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-5752944655d749a0.js" defer=""></script><script src="/_next/static/chunks/framework-a87821de553db91d.js" defer=""></script><script src="/_next/static/chunks/main-6a269cfcb9446759.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fb0512e25146295.js" defer=""></script><script src="/_next/static/chunks/286-30519d8a3e60551d.js" defer=""></script><script src="/_next/static/chunks/807-a4eae1dfa8bfbe9f.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-44fac0971625f498.js" defer=""></script><script src="/_next/static/dF3nvRRG-dFmoFK9qwTLn/_buildManifest.js" defer=""></script><script src="/_next/static/dF3nvRRG-dFmoFK9qwTLn/_ssgManifest.js" defer=""></script><script src="/_next/static/dF3nvRRG-dFmoFK9qwTLn/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><div class="w-screen full-container flex-col md:flex-row flex "><div class="md:basis-1/5 "><div class="navbar fixed w-full flex md:flex-col px-4 md:px-6 py-2 md:py-6 md:pb-7 z-30 bg-sky text-paper md:h-full items-center justify-between md:static md:w-auto md:bg-paper md:text-sky md:max-h-screen md:justify-between child:pl-2 child:md:pl-0 child:text-lg "><div><p class="text-4xl md:text-7xl cursor-pointer font-bold pl-0 md:pb-3">LAION</p><div class="md:flex child:pl-3 md:text-xl child:md:pl-1 child:md:pt-2 hidden md:flex-col child:brightness-100 child:transition"><a href="/projects/">Projects</a><a href="/team/">Team</a><a href="/blog/">Blog</a><a href="/notes/">Notes</a><a href="/press/">Press</a><a href="/about/">About</a><a href="/faq/">FAQ</a><a href="/donations/">Donations</a><a href="/privacy-policy/">Privacy Policy</a><a href="/dataset-requests/">Dataset Requests</a><a href="/impressum/">Impressum</a></div></div><div class="child:mr-3 -ml-0.5 child:w-8 child:brightness-100 child:transition hidden md:flex"><a href="mailto:contact@laion.ai" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg></a><a href="https://discord.com/invite/eq3cAMZtCC" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a><a href="https://github.com/LAION-AI/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></div><div class="md:hidden"><div><div class="bm-overlay" style="position:fixed;z-index:1000;width:100%;height:100%;background:rgba(0, 0, 0, 0.3);opacity:0;-moz-transform:translate3d(100%, 0, 0);-ms-transform:translate3d(100%, 0, 0);-o-transform:translate3d(100%, 0, 0);-webkit-transform:translate3d(100%, 0, 0);transform:translate3d(100%, 0, 0);transition:opacity 0.3s, transform 0s 0.3s;top:0px;left:0px"></div><div><div class="bm-burger-button" style="z-index:1000;position:fixed;width:1.2em;height:1.0em;right:1.2rem;top:1em"><button type="button" id="react-burger-menu-btn" style="position:absolute;left:0;top:0;z-index:1;width:100%;height:100%;margin:0;padding:0;border:none;font-size:0;background:transparent;cursor:pointer">Open Menu</button><span><span class="bm-burger-bars" style="position:absolute;height:20%;left:0;right:0;top:0%;opacity:1;background:#fff"></span><span class="bm-burger-bars" style="position:absolute;height:20%;left:0;right:0;top:40%;opacity:1;background:#fff"></span><span class="bm-burger-bars" style="position:absolute;height:20%;left:0;right:0;top:80%;opacity:1;background:#fff"></span></span></div></div><div id="" class="bm-menu-wrap" style="position:fixed;right:0;z-index:1100;width:300px;height:100%;-moz-transform:translate3d(100%, 0, 0);-ms-transform:translate3d(100%, 0, 0);-o-transform:translate3d(100%, 0, 0);-webkit-transform:translate3d(100%, 0, 0);transform:translate3d(100%, 0, 0);transition:all 0.5s;top:0px" aria-hidden="true"><div class="bm-menu" style="height:100%;box-sizing:border-box;overflow:auto;background:#1D374E;padding:2.5em 1.5em 0"><nav class="bm-item-list" style="height:100%;color:#fff;padding:0.8em"><div class="bm-item" style="display:inline-block" tabindex="-1"><div class="child:pb-2 child:child:text-2xl"><p><a href="/projects/">Projects</a></p><p><a href="/team/">Team</a></p><p><a href="/blog/">Blog</a></p><p><a href="/notes/">Notes</a></p><p><a href="/press/">Press</a></p><p><a href="/about/">About</a></p><p><a href="/faq/">FAQ</a></p><p><a href="/donations/">Donations</a></p><p><a href="/privacy-policy/">Privacy Policy</a></p><p><a href="/dataset-requests/">Dataset Requests</a></p><p><a href="/impressum/">Impressum</a></p></div><div class="child:mr-3 pt-4 child:w-8 child:brightness-100 hover:child:brightness-90 child:transition flex"><a href="mailto:contact@laion.ai" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg></a><a href="https://discord.com/invite/eq3cAMZtCC" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a><a href="https://github.com/LAION-AI/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></div></div></nav></div><div><div class="bm-cross-button" style="position:absolute;width:24px;height:24px;right:8px;top:8px"><button type="button" id="react-burger-cross-btn" style="position:absolute;left:0;top:0;z-index:1;width:100%;height:100%;margin:0;padding:0;border:none;font-size:0;background:transparent;cursor:pointer" tabindex="-1">Close Menu</button><span style="position:absolute;top:6px;right:14px"><span class="bm-cross" style="position:absolute;width:3px;height:14px;transform:rotate(45deg);background:#fff"></span><span class="bm-cross" style="position:absolute;width:3px;height:14px;transform:rotate(-45deg);background:#fff"></span></span></div></div></div></div></div></div></div><div id="content" class="md:overflow-y-scroll md:max-h-screen md:z-50 md:shadow-lg shadow-neutral-600/70 text-paper grow md:grow-0 md:basis-4/5 flex child:grow flex-col "><div class="" style="opacity:0"><div class="w-full flex justify-center py-5 pt-16 md:pt-5"><div class="container px-5" lang="en"><h1 lang="en" style="hyphens:auto" class="text-8xl md:text-8xl w-full font-bold title-flow break-words">INTRODUCING BUD-E 1.0: AI-ASSISTED EDUCATION FOR EVERYONE</h1><p class="text-2xl pb-2">by: <!-- -->LAION<!-- -->,<!-- --> <!-- -->20 Jan, 2025<!-- --></p><hr/><div class="pt-2 article"><p>Today marks a milestone in our journey towards democratizing education and empathy through technology. LAION e.V. <em>is thrilled to announce the release of BUD-E</em> version 1.0, an open-source, privacy-compliant AI education assistant framework.</p>
<p>BUD-E, which stands for Buddy for Understanding and Digital Empathy, represents our first step towards realizing a grand vision: providing every person on Earth with access to a free, intelligent, and caring education assistant. This release includes three distinct versions tailored to different needs:</p>
<ul>
<li>School Bud-E, a specialized web-based version for educational settings.</li>
<li>Bud-E, a general-purpose, customizable web-based assistant.</li>
<li>Desktop Bud-E, a Python*-based desktop application that can be used as a smart Google Home/Alexa Replacement with wake word activation and the latest models in the backend.</li>
</ul>
<p>Overview (what it can do):</p>
<p><a href="https://www.youtube.com/watch?v=gcSPuZ7LtE0"><img src="https://github.com/user-attachments/assets/ae86cb13-38fe-4768-be46-5353f2f58bb9" alt="School Bud-E Video"></a></p>
<p>How to use Bud-E &amp; School Bud-E:</p>
<p><a href="https://www.youtube.com/watch?v=IxHnpISMNPo"><img src="https://github.com/user-attachments/assets/02f1458e-d46f-4352-b44e-bb72165eb26e" alt="School Bud-E Video 2"></a></p>
<h2><a id="bud-e-a-new-era-of-ai-assisted-education" class="anchor" href="#bud-e-a-new-era-of-ai-assisted-education" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>BUD-E: A New Era of AI-Assisted Education</h2>
<p>The Large-scale Artificial Intelligence Open Network (LAION) collaborates with Intel as part of the new AI/oneAPI Center of Excellence (CoE) we established in September last year.</p>
<p>Our CoE's mission is to advance the development of BUD-E, an open source, empathetic AI education assistant that aims to democratize personalized learning worldwide. LAION is proud to work with Intel, famous for the International Science and Engineering Fair founded by former Intel CEO Gordon Moore.</p>
<p>We hope to replicate the mentorship and resources that used to be only available to a select few,
scale it to the extent that every child in the world has access to a personalized education and the deep knowledge that used to be siloed in only the most prestigious educational institutions.</p>
<p>For our development, we actively leveraged the new Intel® Core™ Ultra Processors Series 2 AI PCs as well as Intel® Neural Compressor, OpenVINO™, and Intel® Optimizations for PyTorch*.</p>
<p>These components helped us to design our local first” peer-to-peer MLops architecture that preserves the children’s privacy. This peer-to-peer integration to individual nodes asks computers within its zone of trust, for machine learning inference, datasets, and models, using them as tools that the local language model can use to compose the correct answer,</p>
<p>For example, schools can utilize the Open Platform for Enterprise AI (OPEA*) to generate a graphrag of the school curriculum, serve Llama 3.1 405b, a video diffusion model, provide storage, or other things that won’t fit on a laptop form factor. It will also allow parents to put guardrails on the language model’s outputs, customize the curriculum or the special needs that the child needs help with, and collaborate with peers via a real-time generative AI-enabled whiteboard experience.</p>
<h2><a id="a-vision-of-universal-access-to-personalized-learning" class="anchor" href="#a-vision-of-universal-access-to-personalized-learning" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>A Vision of Universal Access to Personalized Learning</h2>
<p>Imagine a world where every child, regardless of background or circumstances, has a personal AI tutor available 24/7. A world where adults seeking to learn new skills or change careers have a patient, understanding guide to help them along their journey. This is the future we're working towards with BUD-E.</p>
<p>We believe education is the great equalizer, the key to unlocking human potential and fostering understanding between people of all backgrounds. However, access to quality, personalized education remains a privilege accessible for too few. Technology, particularly AI, has the potential to change this – not by replacing human teachers but by augmenting and extending their reach.</p>
<p>BUD-E embodies our belief that an AI assistant can be more than just a source of information. We envision it as a companion in the learning journey – one that's empathetic, encouraging, and adapted to each individual's unique learning style and needs. While we just started on the road towards fully realizing our vision, BUD-E 1.0 and its specialized variants lay the groundwork for this ambitious goal.</p>
<h2><a id="the-path-to-democratizing-empathy-and-education" class="anchor" href="#the-path-to-democratizing-empathy-and-education" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The Path to Democratizing Empathy and Education</h2>
<p>Several core principles guide our journey with BUD-E:</p>
<ol>
<li><strong>Accessibility</strong>: Education should be available to everyone, regardless of financial means or geographic location.</li>
<li><strong>Privacy</strong>: Learning is a personal journey, and users' data should be protected and respected.</li>
<li><strong>Transparency</strong>: As an open-source project, BUD-E's workings are open for scrutiny and improvement by the community.</li>
<li><strong>Adaptability</strong>: Every learner is unique, and educational tools should adapt to individual needs and preferences.</li>
<li><strong>Empathy</strong>: Effective learning requires not just information but understanding, encouragement, and emotional support.</li>
</ol>
<p>These principles are at the heart of the design of all BUD-E versions and will continue to guide their development.</p>
<h2><a id="school-bud-e-an-ai-learning-companion-for-the-classroom" class="anchor" href="#school-bud-e-an-ai-learning-companion-for-the-classroom" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>School Bud-E: An AI Learning Companion for the Classroom</h2>
<p>In collaboration with the Intel AI Center of Excellence and the German Research Network for AI (DFKI), we're proud to release School Bud-E 1.0, a specialized web-based version of BUD-E designed to enhance the educational experience for students and teachers alike.</p>
<p>School Bud-E is more than just a chatbot; it's a privacy-first AI learning companion that brings a new dimension of support and engagement to the classroom. Here are some of its key features:</p>
<ul>
<li><strong>Privacy Compliance</strong>: All interactions within School Bud-E are only stored locally in the user's browser. Using self-hosted or privacy-compliant APIs ensures that sensitive student data remains protected and private.</li>
<li><strong>Inspiring Learning Support</strong>: School Bud-E features a carefully crafted system prompt that fosters engaging, age-appropriate interactions. It's designed to adapt to each student's learning style, providing encouragement and sparking curiosity.</li>
<li><strong>Wikipedia Integration</strong>: The assistant can access Wikipedia* and provide information on request. For access, use #wikipedia: KEYWORDS:TOP_N; to specify the database, use #wikipedia_de or #wikipedia_en. We provide endpoints for searching in vector databases with BGE-M3 embeddings for English and German Wikipedia</li>
<li><strong>Curriculum Retrieval</strong>: Teachers can effortlessly search school curricula using custom database endpoints, enabling School Bud-E to perform retrieval-augmented generation. Our system comes with an endpoint that performs Best Match 25 (BM25) search in all public school curricula of the German state of Hamburg. Simply use commands like #bildungsplan: KEYWORDS:TOP_N (e.g., #bildungsplan: artificial intelligence:5).</li>
<li><strong>Scientific Paper Retrieval</strong>: School Bud-E can search through more than 85 million abstracts of scientific papers provided by the ASK* Open Research Knowledge Graph Initiative from the University of Hannover. For instance, using the command #papers: quantum computing:3 will retrieve the top three papers related to quantum computing, while #papers: climate change impacts:5 would return the top five papers on the impacts of climate change. Importantly, just like with Wikipedia and curriculum integration, the endpoint for this scientific paper database can be replaced with custom endpoints, allowing schools to integrate their own preferred research databases.</li>
<li><strong>Automated Assessment</strong>: School Bud-E can help with suggestions for homework or test corrections using multimodal evaluation that combines optical character recognition (OCR) and AI, providing fair and consistent assessment of homework and exams. Simply upload images of the tests and use the #correction or #korrektur command.</li>
<li><strong>Natural Conversations</strong>: Powered by advanced automatic speech recognition (ASR) and text-to-speech (TTS) technology, School Bud-E offers responsive voice interactions, enabling users to use the system like a voice message app.</li>
<li><strong>Flexible Deployment</strong>: School Bud-E can be deployed using Docker Compose for ease of setup or run locally using a Deno server, providing flexibility for different technical environments.</li>
<li><strong>Multilingual Support</strong>: School Bud-E can support over 100 languages depending on the APIs used. For example, combining Whisper and a Fish TTS 1.5 School Bud-E can understand and reply with text-to-speech output in 11 languages. Similarly, combining Whisper and camb.ai’s MARS6 model, Bud-E can reply in over 100 languages in the same voice, creating unparalleled accessibility for students from diverse cultures and backgrounds.</li>
<li><strong>Universal API Key</strong>: Instead of providing several API keys, URLs, and models for each category, we now also offer the input of a single universal API key that automatically makes use of the default text-generation, speech-to-text, text-to-speech, and vision-language model</li>
</ul>
<h2><a id="a-web-based-frontend-for-easy-access" class="anchor" href="#a-web-based-frontend-for-easy-access" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>A Web-Based Frontend for Easy Access</h2>
<p>The <a href="https://github.com/LAION-AI/school-bud-e-frontend">School Bud-E web frontend</a> allows students and teachers to interact with the assistant directly from their browsers without needing to install any software. This web interface is designed for classroom use and offers intuitive voice message interactions similar to popular messaging apps.</p>
<h2><a id="customizable-backend-for-enhanced-flexibility" class="anchor" href="#customizable-backend-for-enhanced-flexibility" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Customizable Backend for Enhanced Flexibility</h2>
<p>School Bud-E allows users to specify their own API endpoints and backend models. This means schools can choose the AI models that best fit their needs and resources, whether self-hosted open-source models or commercial APIs.</p>
<h2><a id="bud-e-your-customizable-general-purpose-ai-companion-web-based" class="anchor" href="#bud-e-your-customizable-general-purpose-ai-companion-web-based" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Bud-E: Your Customizable, General-Purpose AI Companion (Web-Based)</h2>
<p>We're also introducing Bud-E, a browser-based AI assistant that empowers users to customize their experience fully. This version puts the power of choice in your hands, allowing you to tailor the assistant to a wide range of tasks and preferences.</p>
<p>The key difference between Bud-E and School Bud-E is that Bud-E provides more freedom to define its personality by specifying your own system prompt. Whether you want a creative writing assistant, a research companion, or a friendly conversationalist, you're in control.</p>
<h2><a id="desktop-bud-e-10-your-python-based-desktop-ai-assistant" class="anchor" href="#desktop-bud-e-10-your-python-based-desktop-ai-assistant" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Desktop Bud-E 1.0: Your Python-Based Desktop AI Assistant</h2>
<p>For users who prefer a desktop application, we offer <strong>Desktop Bud-E 1.0</strong>, a Python-based client that brings BUD-E's capabilities right to your desktop.</p>
<h3><a id="key-features-of-desktop-buddy" class="anchor" href="#key-features-of-desktop-buddy" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Key Features of Desktop Buddy</h3>
<ul>
<li><strong>Desktop Integration</strong>: Desktop Bud-E functions similarly to Microsoft Copilot, integrating seamlessly with your desktop environment.</li>
<li><strong>Screenshot and Clipboard Interaction</strong>: Capture screenshots and interact with your clipboard, allowing Desktop Buddy to understand and assist with many varied tasks.
Local Command Execution: Execute local commands, further extending Desktop Buddy's capabilities.</li>
<li><strong>Modular Design</strong>: Like other BUD-E versions, each component (ASR, LLM, TTS, Vision) can be swapped out or updated independently, ensuring you always have access to the best tools.</li>
<li><strong>Skill System</strong>: Execute Python functions either on the server or locally, opening up possibilities for various activities, from database queries to interactive experiments.
Tested on Windows and Ubuntu: Desktop Buddy has been thoroughly tested on popular operating systems.</li>
</ul>
<p>Desktop Buddy is ideal for users who want a powerful, locally integrated AI assistant that can interact with their desktop environment and execute local commands.</p>
<h2><a id="technical-foundation-flexibility-and-openness" class="anchor" href="#technical-foundation-flexibility-and-openness" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Technical Foundation: Flexibility and Openness</h2>
<p>All BUD-E versions are built on a flexible client-server architecture. This allows for easy deployment, component upgrades, and adaptation to evolving technology.</p>
<h3><a id="server-components" class="anchor" href="#server-components" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Server Components</h3>
<ol>
<li><strong>Automatic Speech Recognition (ASR)</strong>: The ears of BUD-E, converting speech to text.</li>
<li><strong>Language Model (LLM)</strong>: The brain of BUD-E, processing text and generating responses.</li>
<li><strong>Text-to-Speech (TTS)</strong>: The voice of BUD-E, converting text responses to speech.</li>
<li><strong>Vision Processing</strong>: The eyes of BUD-E, handling image captioning and OCR.</li>
</ol>
<h2><a id="the-road-ahead" class="anchor" href="#the-road-ahead" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The Road Ahead</h2>
<p>We are under no illusions about the challenges ahead. Creating an AI assistant that truly understands and empathizes with learners, can explain complex concepts intuitively, and can foster a love of learning is an enormous task. BUD-E 1.0 in its different versions is but a small first step. It is important to note that the current version of BUD-E does not yet possess the capability to understand users' emotions, and BUD-E 1.0 is not intended to be used for emotion recognition. The purpose of BUD-E 1.0 is not to identify or infer emotions or intentions of natural persons on the basis of their biometric data, as defined under the European Union's AI Act. While basic emotion recognition could be helpful to the learner, for example by encouraging a learner whose voice sounds discouraged, we believe deployment should be cautious, transparent and responsible. We believe these features could be implemented by leveraging multimodal APIs like Gemini Audio or HUME AI for emotion recognition, but we have not yet integrated these features due to time constraints and regulatory considerations.</p>
<p>AI systems intended to be used for emotion recognition are classified as high-risk under <a href="https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=OJ:L_202401689#anx_III">Annex III of the European Union's AI Act</a>. Therefore, we do not recommend implementing and putting into practice any empathetic voice assistance capable of understanding users' emotions in the European Union yet without careful review. However, we firmly believe that empathetic AI assistants hold immense potential for creating more engaging and curiosity-sparking educational experiences. The ability to connect with users on an emotional level, in addition to an intellectual one, is a crucial ingredient for building systems that can truly help individuals explore the world more holistically. As such, we plan to pursue, in consultation with our EU attorneys, the development of empathetic voice assistance in general and also specifically for educational settings where safety measures could allow for emotion detection.</p>
<p>Beyond developing empathetic capabilities, our roadmap includes improving natural language understanding and expanding the skill library; including more advanced tools for research, interactive learning, and other tasks.</p>
<h2><a id="credits-and-thanks" class="anchor" href="#credits-and-thanks" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Credits and Thanks</h2>
<p>The LAION team closely collaborates with Intel’s Jayaraman Mahalingam (Jay) and Desmond Greely to make our vision a reality.</p>
<p>Jay provided LAION with Access to the new Intel® Core™ Ultra Processors Series 2 (formerly code-named Lunar Lake) AI PCs using Intel® Neural Compressor, OpenVINO™ and Intel® Optimizations for PyTorch.</p>
<p>Desmond additionally provided the LAION team with access to cutting-edge Intel® Gaudi® AI Accelerators, to train Llama language models capable of driving 3d Avatars, by teaching language models how to express themselves emotionally and thoughtfully with audio tokens, chain of thought tokens, and body pose tokens using PyTorch Lightning.</p>
<p>We also thank</p>
<p>Hamburg’s <a href="https://www.hamburg.de/politik-und-verwaltung/behoerden/schulbehoerde">Behörde für Schule und and Berufsbildung (BSB)</a>, and  specifically <a href="https://bildungsserver.hamburg.de/schulfaecher/kontakt-mint-referat-710650">Dr. Najibulla Karim</a> and <a href="https://jtschindler.github.io/">Dr. Janosch Schindler</a> for their great feedback and support.</p>
<p>Hallucinate LLC, and specifically <a href="https://github.com/endomorphosis/">Benjamin Barber</a> and his partners <a href="https://github.com/mwni">Marc-Emanuel Otto</a> and <a href="https://github.com/coregod360">Kevin De Haan</a>, for being willing to open source parts of their previous MLops architecture, and donating their time and effort to create a new MLops architecture to support the LAION  educational mission.</p>
<p><a href="https://github.com/Robinysh">Robin Yuen Shing Hei</a>, who helped us prototype the model training code for a llama based audio language modeling presented at Neurips <a href="https://arxiv.org/abs/2409.17353">Internalizing ASR with Implicit Chain of Thought for Efficient Speech-to-Speech Conversational LLM</a>, and we wish him luck in his new role at Soundhound.</p>
<p>John Oberg of <a href="https://www.komagome.ed.jp/education/steam.php">Komagome Gakuen High School</a> for evaluating the impact of large language models on English language learners in Japan, and developing lesson plans to integrate LLMs into the classroom.</p>
<h2><a id="join-us-in-revolutionizing-education" class="anchor" href="#join-us-in-revolutionizing-education" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Join Us in Revolutionizing Education</h2>
<p>We believe that by working together – developers, educators, researchers, students, and enthusiasts – we can create an AI assistant that truly empowers learners worldwide. BUD-E is more than just a software project; it's a movement towards a future where quality, personalized education is a right, not a privilege.</p>
<p>Whether you're interested in contributing code, testing the system in educational settings, or simply providing feedback on your experiences, your input is invaluable. Every contribution, no matter how small, brings us one step closer to a world where everyone has access to the education they need to thrive.</p>
<p>To get involved or learn more about BUD-E, you can test the web versions of the
BUD-E Personal Assistant and School BUD-E today.</p>
<p>You can also</p>
<ul>
<li>Visit our GitHub repositories</li>
<li>Join our community Discord</li>
<li>Reach out to us at <a href="mailto:bud-e@laion.ai">bud-e@laion.ai</a></li>
</ul>
<p>Let's work together to unlock the potential of every learner, foster global understanding, and create a brighter future for all.</p>
<h2><a id="download-and-contribute" class="anchor" href="#download-and-contribute" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Download and Contribute</h2>
<p>The journey of a thousand miles begins with a single step. BUD-E 1.0 is our first step. Will you take the next one with us?</p>
<ul>
<li><a href="https://github.com/LAION-AI/bud-e/tree/main">LAION-AI/bud-e</a>: A general human-ai interaction platform.</li>
<li><a href="https://github.com/LAION-AI/school-bud-e-frontend">LAION-AI/school-bud-e-frontend</a>: A frontend that is compatible to the school-bud-e-backend.</li>
<li><a href="https://github.com/LAION-AI/Desktop-BUD-E_V1.0">LAION-AI/Desktop-BUD-E_V1.0</a>: BUD-E (Buddy) is an open-source voice assistant framework that facilitates seamless interaction with AI models and APIs, enabling the creation and integration of diverse skills for educational and research applications.</li>
</ul>
<p>Together, we can transform education, one conversation at a time.</p>
<p>We encourage you to check out and incorporate Intel’s other <a href="https://www.intel.com/content/www/us/en/developer/tools/frameworks/overview.html">AI/ML Framework optimizations and tools</a> into your AI workflow and learn about the unified, open, standards-based <a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/overview.html">oneAPI</a> programming model that forms the foundation of Intel’s <a href="https://www.intel.com/content/www/us/en/developer/topic-technology/artificial-intelligence/overview.html">AI Software Portfolio</a> to help you prepare, build, deploy, and scale your AI solutions.</p>
<h2><a id="additional-resources" class="anchor" href="#additional-resources" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Additional Resources</h2>
<ul>
<li><a href="https://www.intel.com/content/www/us/en/developer/topic-technology/artificial-intelligence/overview.html">Intel AI Developer Tools and resources</a></li>
<li><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/overview.html%23gs.h7kofh">oneAPI unified programming model</a></li>
<li><a href="https://www.intel.com/content/www/us/en/developer/topic-technology/artificial-intelligence/training/generative-ai.html">Generative AI</a></li>
</ul>
</div></div></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontmatter":{"title":"Introducing BUD-E 1.0: AI-Assisted Education for Everyone","author":"LAION","date":"Jan 20 2025","previewImg":"/images/blog/bud-e-1.0.png"},"content":"\nToday marks a milestone in our journey towards democratizing education and empathy through technology. LAION e.V. *is thrilled to announce the release of BUD-E* version 1.0, an open-source, privacy-compliant AI education assistant framework.\n\nBUD-E, which stands for Buddy for Understanding and Digital Empathy, represents our first step towards realizing a grand vision: providing every person on Earth with access to a free, intelligent, and caring education assistant. This release includes three distinct versions tailored to different needs:\n\n- School Bud-E, a specialized web-based version for educational settings.\n- Bud-E, a general-purpose, customizable web-based assistant.\n- Desktop Bud-E, a Python*-based desktop application that can be used as a smart Google Home/Alexa Replacement with wake word activation and the latest models in the backend.\n\nOverview (what it can do):\n\n[![School Bud-E Video](https://github.com/user-attachments/assets/ae86cb13-38fe-4768-be46-5353f2f58bb9)](https://www.youtube.com/watch?v=gcSPuZ7LtE0)\n\nHow to use Bud-E \u0026 School Bud-E:\n\n[![School Bud-E Video 2](https://github.com/user-attachments/assets/02f1458e-d46f-4352-b44e-bb72165eb26e)](https://www.youtube.com/watch?v=IxHnpISMNPo)\n\n\n## BUD-E: A New Era of AI-Assisted Education\n\nThe Large-scale Artificial Intelligence Open Network (LAION) collaborates with Intel as part of the new AI/oneAPI Center of Excellence (CoE) we established in September last year.\n\nOur CoE's mission is to advance the development of BUD-E, an open source, empathetic AI education assistant that aims to democratize personalized learning worldwide. LAION is proud to work with Intel, famous for the International Science and Engineering Fair founded by former Intel CEO Gordon Moore.\n\nWe hope to replicate the mentorship and resources that used to be only available to a select few,\nscale it to the extent that every child in the world has access to a personalized education and the deep knowledge that used to be siloed in only the most prestigious educational institutions.\n\nFor our development, we actively leveraged the new Intel® Core™ Ultra Processors Series 2 AI PCs as well as Intel® Neural Compressor, OpenVINO™, and Intel® Optimizations for PyTorch*.\n\nThese components helped us to design our local first” peer-to-peer MLops architecture that preserves the children’s privacy. This peer-to-peer integration to individual nodes asks computers within its zone of trust, for machine learning inference, datasets, and models, using them as tools that the local language model can use to compose the correct answer,\n\nFor example, schools can utilize the Open Platform for Enterprise AI (OPEA*) to generate a graphrag of the school curriculum, serve Llama 3.1 405b, a video diffusion model, provide storage, or other things that won’t fit on a laptop form factor. It will also allow parents to put guardrails on the language model’s outputs, customize the curriculum or the special needs that the child needs help with, and collaborate with peers via a real-time generative AI-enabled whiteboard experience.\n\n## A Vision of Universal Access to Personalized Learning\n\nImagine a world where every child, regardless of background or circumstances, has a personal AI tutor available 24/7. A world where adults seeking to learn new skills or change careers have a patient, understanding guide to help them along their journey. This is the future we're working towards with BUD-E.\n\nWe believe education is the great equalizer, the key to unlocking human potential and fostering understanding between people of all backgrounds. However, access to quality, personalized education remains a privilege accessible for too few. Technology, particularly AI, has the potential to change this – not by replacing human teachers but by augmenting and extending their reach.\n\nBUD-E embodies our belief that an AI assistant can be more than just a source of information. We envision it as a companion in the learning journey – one that's empathetic, encouraging, and adapted to each individual's unique learning style and needs. While we just started on the road towards fully realizing our vision, BUD-E 1.0 and its specialized variants lay the groundwork for this ambitious goal.\n\n## The Path to Democratizing Empathy and Education\n\nSeveral core principles guide our journey with BUD-E:\n\n1. **Accessibility**: Education should be available to everyone, regardless of financial means or geographic location.\n2. **Privacy**: Learning is a personal journey, and users' data should be protected and respected.\n3. **Transparency**: As an open-source project, BUD-E's workings are open for scrutiny and improvement by the community.\n4. **Adaptability**: Every learner is unique, and educational tools should adapt to individual needs and preferences.\n5. **Empathy**: Effective learning requires not just information but understanding, encouragement, and emotional support.\n\nThese principles are at the heart of the design of all BUD-E versions and will continue to guide their development.\n\n## School Bud-E: An AI Learning Companion for the Classroom\n\nIn collaboration with the Intel AI Center of Excellence and the German Research Network for AI (DFKI), we're proud to release School Bud-E 1.0, a specialized web-based version of BUD-E designed to enhance the educational experience for students and teachers alike.\n\nSchool Bud-E is more than just a chatbot; it's a privacy-first AI learning companion that brings a new dimension of support and engagement to the classroom. Here are some of its key features:\n\n- **Privacy Compliance**: All interactions within School Bud-E are only stored locally in the user's browser. Using self-hosted or privacy-compliant APIs ensures that sensitive student data remains protected and private.\n- **Inspiring Learning Support**: School Bud-E features a carefully crafted system prompt that fosters engaging, age-appropriate interactions. It's designed to adapt to each student's learning style, providing encouragement and sparking curiosity.\n- **Wikipedia Integration**: The assistant can access Wikipedia* and provide information on request. For access, use #wikipedia: KEYWORDS:TOP_N; to specify the database, use #wikipedia_de or #wikipedia_en. We provide endpoints for searching in vector databases with BGE-M3 embeddings for English and German Wikipedia\n- **Curriculum Retrieval**: Teachers can effortlessly search school curricula using custom database endpoints, enabling School Bud-E to perform retrieval-augmented generation. Our system comes with an endpoint that performs Best Match 25 (BM25) search in all public school curricula of the German state of Hamburg. Simply use commands like #bildungsplan: KEYWORDS:TOP_N (e.g., #bildungsplan: artificial intelligence:5).\n- **Scientific Paper Retrieval**: School Bud-E can search through more than 85 million abstracts of scientific papers provided by the ASK* Open Research Knowledge Graph Initiative from the University of Hannover. For instance, using the command #papers: quantum computing:3 will retrieve the top three papers related to quantum computing, while #papers: climate change impacts:5 would return the top five papers on the impacts of climate change. Importantly, just like with Wikipedia and curriculum integration, the endpoint for this scientific paper database can be replaced with custom endpoints, allowing schools to integrate their own preferred research databases.\n- **Automated Assessment**: School Bud-E can help with suggestions for homework or test corrections using multimodal evaluation that combines optical character recognition (OCR) and AI, providing fair and consistent assessment of homework and exams. Simply upload images of the tests and use the #correction or #korrektur command.\n- **Natural Conversations**: Powered by advanced automatic speech recognition (ASR) and text-to-speech (TTS) technology, School Bud-E offers responsive voice interactions, enabling users to use the system like a voice message app.\n- **Flexible Deployment**: School Bud-E can be deployed using Docker Compose for ease of setup or run locally using a Deno server, providing flexibility for different technical environments.\n- **Multilingual Support**: School Bud-E can support over 100 languages depending on the APIs used. For example, combining Whisper and a Fish TTS 1.5 School Bud-E can understand and reply with text-to-speech output in 11 languages. Similarly, combining Whisper and camb.ai’s MARS6 model, Bud-E can reply in over 100 languages in the same voice, creating unparalleled accessibility for students from diverse cultures and backgrounds.\n- **Universal API Key**: Instead of providing several API keys, URLs, and models for each category, we now also offer the input of a single universal API key that automatically makes use of the default text-generation, speech-to-text, text-to-speech, and vision-language model\n\n## A Web-Based Frontend for Easy Access\n\nThe [School Bud-E web frontend](https://github.com/LAION-AI/school-bud-e-frontend) allows students and teachers to interact with the assistant directly from their browsers without needing to install any software. This web interface is designed for classroom use and offers intuitive voice message interactions similar to popular messaging apps.\n\n## Customizable Backend for Enhanced Flexibility\n\nSchool Bud-E allows users to specify their own API endpoints and backend models. This means schools can choose the AI models that best fit their needs and resources, whether self-hosted open-source models or commercial APIs.\n\n## Bud-E: Your Customizable, General-Purpose AI Companion (Web-Based)\n\nWe're also introducing Bud-E, a browser-based AI assistant that empowers users to customize their experience fully. This version puts the power of choice in your hands, allowing you to tailor the assistant to a wide range of tasks and preferences.\n\nThe key difference between Bud-E and School Bud-E is that Bud-E provides more freedom to define its personality by specifying your own system prompt. Whether you want a creative writing assistant, a research companion, or a friendly conversationalist, you're in control.\n\n## Desktop Bud-E 1.0: Your Python-Based Desktop AI Assistant\n\nFor users who prefer a desktop application, we offer **Desktop Bud-E 1.0**, a Python-based client that brings BUD-E's capabilities right to your desktop.\n\n### Key Features of Desktop Buddy\n\n- **Desktop Integration**: Desktop Bud-E functions similarly to Microsoft Copilot, integrating seamlessly with your desktop environment.\n- **Screenshot and Clipboard Interaction**: Capture screenshots and interact with your clipboard, allowing Desktop Buddy to understand and assist with many varied tasks.\nLocal Command Execution: Execute local commands, further extending Desktop Buddy's capabilities.\n- **Modular Design**: Like other BUD-E versions, each component (ASR, LLM, TTS, Vision) can be swapped out or updated independently, ensuring you always have access to the best tools.\n- **Skill System**: Execute Python functions either on the server or locally, opening up possibilities for various activities, from database queries to interactive experiments.\nTested on Windows and Ubuntu: Desktop Buddy has been thoroughly tested on popular operating systems.\n\nDesktop Buddy is ideal for users who want a powerful, locally integrated AI assistant that can interact with their desktop environment and execute local commands.\n\n## Technical Foundation: Flexibility and Openness\n\nAll BUD-E versions are built on a flexible client-server architecture. This allows for easy deployment, component upgrades, and adaptation to evolving technology.\n\n### Server Components\n\n1. **Automatic Speech Recognition (ASR)**: The ears of BUD-E, converting speech to text.\n2. **Language Model (LLM)**: The brain of BUD-E, processing text and generating responses.\n3. **Text-to-Speech (TTS)**: The voice of BUD-E, converting text responses to speech.\n4. **Vision Processing**: The eyes of BUD-E, handling image captioning and OCR.\n\n## The Road Ahead\n\nWe are under no illusions about the challenges ahead. Creating an AI assistant that truly understands and empathizes with learners, can explain complex concepts intuitively, and can foster a love of learning is an enormous task. BUD-E 1.0 in its different versions is but a small first step. It is important to note that the current version of BUD-E does not yet possess the capability to understand users' emotions, and BUD-E 1.0 is not intended to be used for emotion recognition. The purpose of BUD-E 1.0 is not to identify or infer emotions or intentions of natural persons on the basis of their biometric data, as defined under the European Union's AI Act. While basic emotion recognition could be helpful to the learner, for example by encouraging a learner whose voice sounds discouraged, we believe deployment should be cautious, transparent and responsible. We believe these features could be implemented by leveraging multimodal APIs like Gemini Audio or HUME AI for emotion recognition, but we have not yet integrated these features due to time constraints and regulatory considerations.\n\nAI systems intended to be used for emotion recognition are classified as high-risk under [Annex III of the European Union's AI Act](https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=OJ:L_202401689#anx_III). Therefore, we do not recommend implementing and putting into practice any empathetic voice assistance capable of understanding users' emotions in the European Union yet without careful review. However, we firmly believe that empathetic AI assistants hold immense potential for creating more engaging and curiosity-sparking educational experiences. The ability to connect with users on an emotional level, in addition to an intellectual one, is a crucial ingredient for building systems that can truly help individuals explore the world more holistically. As such, we plan to pursue, in consultation with our EU attorneys, the development of empathetic voice assistance in general and also specifically for educational settings where safety measures could allow for emotion detection.\n\nBeyond developing empathetic capabilities, our roadmap includes improving natural language understanding and expanding the skill library; including more advanced tools for research, interactive learning, and other tasks.\n\n## Credits and Thanks\n\nThe LAION team closely collaborates with Intel’s Jayaraman Mahalingam (Jay) and Desmond Greely to make our vision a reality.\n\nJay provided LAION with Access to the new Intel® Core™ Ultra Processors Series 2 (formerly code-named Lunar Lake) AI PCs using Intel® Neural Compressor, OpenVINO™ and Intel® Optimizations for PyTorch.\n\nDesmond additionally provided the LAION team with access to cutting-edge Intel® Gaudi® AI Accelerators, to train Llama language models capable of driving 3d Avatars, by teaching language models how to express themselves emotionally and thoughtfully with audio tokens, chain of thought tokens, and body pose tokens using PyTorch Lightning.\n\nWe also thank\n\nHamburg’s [Behörde für Schule und and Berufsbildung (BSB)](https://www.hamburg.de/politik-und-verwaltung/behoerden/schulbehoerde), and  specifically [Dr. Najibulla Karim](https://bildungsserver.hamburg.de/schulfaecher/kontakt-mint-referat-710650) and [Dr. Janosch Schindler](https://jtschindler.github.io/) for their great feedback and support.\n\nHallucinate LLC, and specifically [Benjamin Barber](https://github.com/endomorphosis/) and his partners [Marc-Emanuel Otto](https://github.com/mwni) and [Kevin De Haan](https://github.com/coregod360), for being willing to open source parts of their previous MLops architecture, and donating their time and effort to create a new MLops architecture to support the LAION  educational mission.\n\n[Robin Yuen Shing Hei](https://github.com/Robinysh), who helped us prototype the model training code for a llama based audio language modeling presented at Neurips [Internalizing ASR with Implicit Chain of Thought for Efficient Speech-to-Speech Conversational LLM](https://arxiv.org/abs/2409.17353), and we wish him luck in his new role at Soundhound.\n\nJohn Oberg of [Komagome Gakuen High School](https://www.komagome.ed.jp/education/steam.php) for evaluating the impact of large language models on English language learners in Japan, and developing lesson plans to integrate LLMs into the classroom.\n\n## Join Us in Revolutionizing Education\n\nWe believe that by working together – developers, educators, researchers, students, and enthusiasts – we can create an AI assistant that truly empowers learners worldwide. BUD-E is more than just a software project; it's a movement towards a future where quality, personalized education is a right, not a privilege.\n\nWhether you're interested in contributing code, testing the system in educational settings, or simply providing feedback on your experiences, your input is invaluable. Every contribution, no matter how small, brings us one step closer to a world where everyone has access to the education they need to thrive.\n\nTo get involved or learn more about BUD-E, you can test the web versions of the\nBUD-E Personal Assistant and School BUD-E today.\n\nYou can also\n\n- Visit our GitHub repositories\n- Join our community Discord\n- Reach out to us at \u003cbud-e@laion.ai\u003e\n\nLet's work together to unlock the potential of every learner, foster global understanding, and create a brighter future for all.\n\n## Download and Contribute\n\nThe journey of a thousand miles begins with a single step. BUD-E 1.0 is our first step. Will you take the next one with us?\n\n- [LAION-AI/bud-e](https://github.com/LAION-AI/bud-e/tree/main): A general human-ai interaction platform.\n- [LAION-AI/school-bud-e-frontend](https://github.com/LAION-AI/school-bud-e-frontend): A frontend that is compatible to the school-bud-e-backend.\n- [LAION-AI/Desktop-BUD-E_V1.0](https://github.com/LAION-AI/Desktop-BUD-E_V1.0): BUD-E (Buddy) is an open-source voice assistant framework that facilitates seamless interaction with AI models and APIs, enabling the creation and integration of diverse skills for educational and research applications.\n\nTogether, we can transform education, one conversation at a time.\n\nWe encourage you to check out and incorporate Intel’s other [AI/ML Framework optimizations and tools](https://www.intel.com/content/www/us/en/developer/tools/frameworks/overview.html) into your AI workflow and learn about the unified, open, standards-based [oneAPI](https://www.intel.com/content/www/us/en/developer/tools/oneapi/overview.html) programming model that forms the foundation of Intel’s [AI Software Portfolio](https://www.intel.com/content/www/us/en/developer/topic-technology/artificial-intelligence/overview.html) to help you prepare, build, deploy, and scale your AI solutions.\n\n## Additional Resources\n\n- [Intel AI Developer Tools and resources](https://www.intel.com/content/www/us/en/developer/topic-technology/artificial-intelligence/overview.html)\n- [oneAPI unified programming model](https://www.intel.com/content/www/us/en/developer/tools/oneapi/overview.html%23gs.h7kofh)\n- [Generative AI](https://www.intel.com/content/www/us/en/developer/topic-technology/artificial-intelligence/training/generative-ai.html)\n","slug":"bud-e-release"},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"bud-e-release"},"buildId":"dF3nvRRG-dFmoFK9qwTLn","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>