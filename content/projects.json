[
  {
    "name": "Datasets",
    "entries": [
      {
        "name": "LAION-400M",
        "modality": "image/text",
        "status": "Released",
        "desc": "Formerly known as crawling@home (C@H), an openly accessible 400M image-text-pair dataset.",
        "link": "/blog/laion-400-open-dataset"
      },
      {
        "name": "LAION5B",
        "modality": "image/text",
        "status": "Released",
        "desc": "A dataset consisting of 5.85 billion CLIP-filtered image-text pairs, featuring several nearest neighbor indices, an improved web-interface for exploration and subset generation, and detection scores for watermark, NSFW, and toxic content detection.",
        "link": "/blog/laion-5b"
      },
      {
        "name": "Laion-coco",
        "modality": "image/text",
        "status": "Released",
        "desc": "600M captions generated using BLIP from Laion2B-en.",
        "link": "/blog/laion-coco"
      },
      {
        "name": "Laion translated",
        "modality": "image/text",
        "status": "Released",
        "desc": "3B translated samples from Laion5B.",
        "link": "/blog/laion-translated"
      },
      {
        "name": "Clip H/14",
        "modality": "image/text",
        "status": "Released",
        "desc": "The largest open source clip.",
        "link": "/blog/large-openclip"
      },
      {
        "name": "LAION5B High-Res",
        "modality": "image/text",
        "status": "Released",
        "desc": "A subset of the LAION5B database, with high resolution images oveer 1024x1024, containing 170 million samples.",
        "link": "https://huggingface.co/datasets/laion/laion-high-resolution"
      },
      {
        "name": "LAION Aesthetics",
        "modality": "image/text",
        "status": "Released",
        "desc": "A subset of LAION5B that has been estimated by a model trained on top of clip embeddings to contain only aestheticly pleasing images.",
        "link": "https://github.com/LAION-AI/laion-datasets/blob/main/laion-aesthetic.md"
      },
      {
        "name": "LAION-3D",
        "modality": "3d/image/text",
        "status": "Started",
        "desc": "An effort to create a large-scale dataset consisting of 3D models and descriptor pairs.",
        "link": "https://github.com/LAION-AI/laion-3d"
      },
      {
        "name": "Audio Dataset",
        "modality": "text/audio",
        "status": "Started",
        "desc": "An audio dataset for training CLAP and other models, containing a raw and processed dataset, the latter containing .flac files with captions, labels, and other metadata.",
        "link": "https://github.com/LAION-AI/audio-dataset"
      },
      {
        "name": "Watermark Detection",
        "modality": "image/text",
        "kind": "Contrastive",
        "status": "Released",
        "desc": "A repository containing datasets to train a watermark classifier.",
        "link": "https://github.com/LAION-AI/watermark-detection"
      }
    ]
  },
  {
    "name": "Models",
    "entries": [
      {
        "name": "Openclip",
        "modality": "image/text",
        "kind": "Contrastive",
        "status": "released",
        "desc": "An open source implementation of OpenAI's CLIP (Contrastive Language-Image Pre-training).",
        "link": "https://github.com/mlfoundations/open_clip"
      },
      {
        "name": "DALLE-2 Prior/Decoder",
        "modality": "image/text",
        "kind": "Generative",
        "status": "Started",
        "desc": "An implementation of DALL-E 2, OpenAI's text-to-image synthesis neural network, in Pytorch.",
        "link": "https://github.com/lucidrains/DALLE2-pytorch"
      },
      {
        "name": "ClipCap",
        "modality": "image/text",
        "kind": "Generative",
        "status": "Released",
        "desc": "Generate text from embedding, using pretrained encoder and language models.",
        "link": "https://github.com/TheoCoombes/ClipCap"
      },
      {
        "name": "CLAP",
        "modality": "audio/text",
        "kind": "Contrastive",
        "status": "Started",
        "desc": "A Contrastive Language-Audio Pretraining model, like CLIP, for audio.",
        "link": "https://github.com/LAION-AI/CLAP"
      },
      {
        "name": "Video CLIP",
        "modality": "video/text",
        "kind": "Contrastive",
        "status": "Planning",
        "desc": "A contrastive language pretraining model for videos.",
        "link": "https://github.com/LAION-AI/video-clip"
      },
      {
        "name": "Multilingual-CLIP",
        "modality": "image/text",
        "kind": "Contrastive",
        "status": "In progress",
        "desc": "An implementation of OpenAI's CLIP text encoders for any language.",
        "link": "https://github.com/FreddeFrallan/Multilingual-CLIP"
      },
      {
        "name": "NSFW Detection",
        "modality": "image/text",
        "kind": "Contrastive",
        "status": "Released",
        "desc": "A detector for not safe for work content within images using CLIP.",
        "link": "https://github.com/LAION-AI/CLIP-based-NSFW-Detector"
      },
      {
        "name": "Electric Sheep",
        "modality": "image/text/audio/video",
        "kind": "Contrastive/Generative",
        "status": "Started",
        "desc": "Train Contrastive and generative models on all modalities.",
        "link": "https://github.com/LAION-AI/the-big-plan/blob/main/projects/electric-sheep.md"
      }
    ]
  },
  {
    "name": "Tools",
    "entries": [
      {
        "name": "img2dataset",
        "modality": "image/text",
        "status": "Released",
        "desc": "A tool which allows a user to turn large sets of image urls to an image dataset. Can download, resize and package 100M urls in 20 hours on one machine.",
        "link": "https://github.com/rom1504/img2dataset"
      },
      {
        "name": "Clip Retrieval",
        "modality": "image/text",
        "status": "Released",
        "desc": "Allows a user to easily compute clip embeddings and build a clip retrieval system with them. 100M text+image embeddings can be processed in 20 hours using a RTX 3080.",
        "link": "https://github.com/rom1504/clip-retrieval"
      },
      {
        "name": "Crawlingathome-gpu-hcloud",
        "modality": "image/text",
        "status": "Released",
        "desc": "GPU controlled Hetzner Cloud workers swarm for Crawling@Home project.",
        "link": "https://github.com/rvencu/crawlingathome-gpu-hcloud"
      },
      {
        "name": "Clip Benchmark",
        "modality": "image/text",
        "status": "In Progress",
        "desc": "Evaluating CLIP-like models on a standard set of datasets on different tasks such as zero-shot classification and zero-shot retrieval.",
        "link": "https://github.com/LAION-AI/CLIP_benchmark"
      }
    ]
  },
  {
    "name": "Papers",
    "entries": [
      {
        "name": "LAION-400M",
        "modality": "image/text",
        "status": "Published",
        "link": "https://arxiv.org/abs/2111.02114"
      },
      {
        "name": "LAION-5B",
        "modality": "image/text",
        "status": "started",
        "link": "https://github.com/LAION-AI/laion5B-paper"
      }
    ]
  }
]
